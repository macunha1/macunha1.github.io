<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Projetos | It's me, Macunha!</title><link>https://macunha.me/pt/project/</link><atom:link href="https://macunha.me/pt/project/index.xml" rel="self" type="application/rss+xml"/><description>Projetos</description><generator>Wowchemy (https://wowchemy.com)</generator><language>pt-br</language><copyright>© 2022 Matheus Cunha</copyright><image><url>https://macunha.me/media/icon_hu176de0364afaeda8922c372b574c3cbf_6946_512x512_fill_lanczos_center_3.png</url><title>Projetos</title><link>https://macunha.me/pt/project/</link></image><item><title>ReclameAQUI Data Lake</title><link>https://macunha.me/pt/project/reclameaqui-data-lake/</link><pubDate>Sun, 21 Jul 2019 00:00:00 +0000</pubDate><guid>https://macunha.me/pt/project/reclameaqui-data-lake/</guid><description>&lt;h1 id="introdução">Introdução&lt;/h1>
&lt;h2 id="resumo">Resumo&lt;/h2>
&lt;p>ReclameAQUI é um negócio interessante e único. É um agregador de conteúdo para
troca de experiências dos clientes (especialmente más experiências) sobre
compras (online e offline). No entanto, vai além de um simples &amp;ldquo;site de
reclamações&amp;rdquo;, oferecendo uma interface para as empresas responderem às
reclamações, ajudando os clientes com seus problemas.&lt;/p>
&lt;p>O serviço é simplesmente o maior neste sentido (mundial) recebendo diariamente
600K visitantes únicos, buscando a reputação de uma empresa antes de fechar um
negócio/compra.&lt;/p>
&lt;h2 id="problema">Problema&lt;/h2>
&lt;p>Apesar de já estarem avançados na abordagem de business digital, tendo a
maioria dos serviços hospedados em Cloud computing e cultura analítica, seu
Data Lake precisava de alguns upgrades. O maior motivador deste projeto foram as
contas altíssimas da GCP, especialmente relacionadas ao consumo de dados no
BigQuery.&lt;/p>
&lt;p>Além das tarefas de redução de custos e otimização do processo de ingestão de
dados, aproveitamos a oportunidade para implementar criptografia de dados
at-rest, governança e obfuscação durante as queries contra o data lake. Tornando
os dados acessíveis por todos na empresa, controlando o acesso e gerenciamento
de identidade através do LDAP (auditando cada acesso, para estar em total
conformidade com a GDPR), pudemos oferecer um Data Lake self-service para que
diferentes atores empresariais pudessem satisfazer suas necessidades &amp;ldquo;bebendo&amp;rdquo;
do lake.&lt;/p>
&lt;h1 id="solução">Solução&lt;/h1>
&lt;h2 id="implementação-técnica">Implementação técnica&lt;/h2>
&lt;p>Os principais objetivos foram otimização de custos do Data Lake existente,
melhoria (e extensão) dos pipelines de ingestão de dados existentes, e
aperfeiçoamentos na segurança.&lt;/p>
&lt;p>Partindo pela otimização de custos do Data Lake, reimplantamos os pipelines de
ingestão de dados, utilizando uma área de &amp;ldquo;landing&amp;rdquo; para dados brutos e
posteriormente transformações eram realizadas para adequar os modelos de dados
desejados. Salvando os resultados em outras camadas do Data Lake, para atingir
maior performance nas queries.&lt;/p>
&lt;p>Removemos as Streaming inserts no BigQuery adicionando um step para fazer load
dos dados ao fim da ingestão. O Apache NiFi foi o principal software responsável
pela orquestração e execução da ingestão de dados, abrangendo também as
melhorias da ingestão de dados através da reengenharia dos processos.&lt;/p>
&lt;p>A auditoria no Data Lake foi gerenciada através do Apache Ranger. Para ter
suporte total, implementamos um driver JDBC usando um componente do Apache
Calcite chamado Avatica. A autenticação para o Apache Ranger passou por um
plugin personalizado (também desenvolvido durante o projeto) para LDAP
consumindo informações de usuários do Google Cloud Identity, refletindo a
organização de grupos e usuários existente do Google Suite.&lt;/p>
&lt;p>Para tornar o jogo mais interessante, containerizamos o workflow e utilizamos
bastante Kubernetes (GKE) para gerenciar estes componentes. A maioria dos
componentes Apache não tinha Helm Charts na época e nós os desenvolvemos e
tornamos alguns open-source.&lt;/p>
&lt;h2 id="impacto-e-resultados">Impacto e resultados&lt;/h2>
&lt;p>Durante o tempo do projeto pudemos medir uma estimativa de aproximadamente 56%
de redução de custos do Data Lake através da otimização de recursos e
reengenharia de processos, especialmente a remoção de Streaming inserts no
BigQuery.&lt;/p>
&lt;p>Obtivemos progresso relevante em termos de segurança e governança durante o
projeto, com a introdução do Apache Ranger e auditoria de acesso e uso do Data
Lake, fornecendo capacidades avançadas de segurança à ReclameAQUI, que se
antecipou frente à LGPD e as preocupações em questão da privacidade dos dados.&lt;/p></description></item><item><title>Clipping Service News OCR</title><link>https://macunha.me/pt/project/clipping-service-news-ocr/</link><pubDate>Tue, 11 Sep 2018 00:00:00 +0000</pubDate><guid>https://macunha.me/pt/project/clipping-service-news-ocr/</guid><description>&lt;h1 id="introdução">Introdução&lt;/h1>
&lt;h2 id="sumário">Sumário&lt;/h2>
&lt;p>Como proprietário do maior conjunto de dados de mídia do Brasil, o líder em
monitoramento de mídia Clipping Service estava com problemas de escalabilidade,
aproximando-se da capacidade máxima de seu data center e de seus &amp;ldquo;leitores&amp;rdquo;.&lt;/p>
&lt;p>Clipping Service opera em grande escala, recebendo cerca de ~4,5K páginas de
mídia por dia de cerca de 300 jornais, tanto na versão digital como na impressa.
Anteriormente os funcionários chamados de &amp;ldquo;leitores&amp;rdquo; eram responsáveis pela
leitura e clipping (adicionando destaque ao conteúdo alvo) para depois serem
repassados para a equipe de &amp;ldquo;revisores&amp;rdquo;.&lt;/p>
&lt;p>Como se o fardo de ler inúmeras páginas por dia não fosse suficiente, a operação
dos leitores começa por volta das 4:30 da manhã quando a &amp;ldquo;primeira leitura&amp;rdquo;
inicia (ou seja, a entrega dos impressos matinais).&lt;/p>
&lt;h2 id="problema">Problema&lt;/h2>
&lt;p>Por mais de 20 anos este conteúdo foi ingerido pelos chamados &amp;ldquo;leitores&amp;rdquo;. Mas,
devido ao advento da internet e do boom da imprensa digital a partir do final
dos anos 90, e atualmente de mídias social as empresas estão transferindo seus
investimentos de clipping para o monitoramento de outras áreas. Exigindo
portanto uma ação do Clipping Service para se manter competitiva no mercado.&lt;/p>
&lt;p>Através da automação da leitura de notícias usando OCR, PLN e inteligência
artificial para categorizar as mídias, o plano era alcançar um maior rendimento
durante a ingestão, dando aos leitores mais tempo livre para revisar o conteúdo.
Consequentemente, alcançar uma maior qualidade no conteúdo, já que nós como
humanos não somos bons em fazer tarefas repetitivas, especialmente quando se
trata de ler páginas intermináveis em busca de nomes e palavras.&lt;/p>
&lt;h1 id="solução">Solução&lt;/h1>
&lt;h2 id="implementação-técnica">Implementação técnica&lt;/h2>
&lt;p>Após algum tempo de pesquisa e benchmarking das alternativas, decidimos usar
Python como linguagem de implementação para lidar com textos, OCR e PLN (usando
NLTK). Dada sua API estendida e bibliotecas para PLN e processamento de imagens.&lt;/p>
&lt;p>Como fornecedor de nuvem escolhemos AWS devido a sua estabilidade e consistência
em relação a outros fornecedores, a conclusão na época foi: AWS possui uma
estimativa de preço 14,67% maior do que a GCP. Entretanto, a popularidade da AWS
é maior do que a GCP, assim como é uma nuvem comprovada em termos de
estabilidade, suporte e integridade. Fazendo uma escolha mais segura por um
preço ligeiramente superior.&lt;/p>
&lt;p>A stack foi: Python 3 usando Dramatiq como biblioteca de processamento de
tarefas, executando OCR por meio do Tesseract, processando texto com NLTK e
imagens com Pillow (wrapper do ImageMagick). Redis foi o mensage broker do
Dramatiq, um banco relacional simples estava no Postgres armazenando métricas
referentes à execução e tínhamos também um Elasticsearch armazenando o conteúdo
processado.&lt;/p>
&lt;p>As solicitações vindas do data center chegaram a um Gateway API, responsável por
executar uma função Lambda, e entregar o resultado do conteúdo.&lt;/p>
&lt;p>A melhor parte do design? Armazenávamos e servimos o conteúdo por meio do AWS
S3. Cada peça foi desenhada com tolerância a falhas, e nós simplesmente
desligávamos toda a infra-estrutura em nuvem depois da operação, para ligar
apenas no dia seguinte.&lt;/p>
&lt;p>Operando apenas das 4h às 14h, um projeto &amp;ldquo;serverless&amp;rdquo; e efêmero com beneficiado
por uma redução de custos em núvem agressiva.&lt;/p>
&lt;h2 id="impacto-e-resultados">Impacto e resultados&lt;/h2>
&lt;p>A Clipping Service reduziu em ~78% o quadro de funcionários da equipe de
leitura, oferecendo contratação interna para outras áreas da empresa e um plano
de demissão voluntário com benefícios, tornando o processo o mais humano
possível para os funcionários que preferissem sair.&lt;/p>
&lt;p>Utilizando automação para tarefas de leitura, a Clipping Service pôde alcançar
melhorias consideráveis durante o processo de ingestão de mídia (cerca de 20
vezes mais rápido), oferecendo maior qualidade no serviço de clipping para seus
clientes e viu a oportunidade de criar posteriormente um serviço de auto-serviço
de recortes de imprensa, uma vez que o custo operacional diminuiu
significativamente.&lt;/p></description></item><item><title>Dotz Data Labs</title><link>https://macunha.me/pt/project/dotz-data-labs/</link><pubDate>Sat, 17 Feb 2018 00:00:00 +0000</pubDate><guid>https://macunha.me/pt/project/dotz-data-labs/</guid><description>&lt;h1 id="introdução">Introdução&lt;/h1>
&lt;h2 id="sumário">Sumário&lt;/h2>
&lt;p>Para poder inovar e se manter em um mercado em constante mudança e
evolução, Dotz passou por um processo de transformação digital e teve
a ajuda de alguns consultores neste percurso.&lt;/p>
&lt;p>Entre as iniciativas para se aproximar de um modelo digital, surgiu a
implementação de um Data Lake, com o requisito de ser &lt;a href="https://en.wikipedia.org/wiki/Serverless_computing" target="_blank" rel="noopener">serverless&lt;/a> e
cloud-native, auxiliando no processo de tomada de decisão e encurtando
o time-to-market durante o lançamento de novos produtos.&lt;/p>
&lt;h2 id="problemática">Problemática&lt;/h2>
&lt;p>A Dotz é uma das maiores empresas no campo de programas de fidelidade no
Brasil, e enfrentaria um grande número de problemas com desconexão de
dados dificultando a análise do comportamento de seus usuários. Como
eles receberam dados de inúmeros supermercados e lojas, é difícil
agrupar os produtos, já que o nome é diferente dependendo da fonte. Para
ajudar nesta análise, eles decidiram construir um Data Lake.&lt;/p>
&lt;h1 id="solução">Solução&lt;/h1>
&lt;h2 id="implementação-técnica">Implementação Técnica&lt;/h2>
&lt;p>Construímos e implantamos uma arquitetura gerenciada da Big Data usando
a Plataforma Cloud do Google (GCP) para suportar esta estratégia e
permitir uma visão de 360 graus dos clientes (usuários com pontos a.k.a.
Dotz) e parceiros que oferecem o programa de fidelidade.&lt;/p>
&lt;p>O design foi focado em serviços gerênciados pela nuvem e serverless
oferecida pelo Google, servindo as principais competências de um Data
Lake como o armazenamento escalável usando o Google Cloud Storage, e o
Google BigQuery. Com parte do processo rodando containerizado em
Kubernetes, responsável pela limpeza de dados e gerenciar o ETL.&lt;/p>
&lt;p>Transmitimos dados com o Apache Beam rodando sob o Google DataFlow,
processamento em massa paralelo com Apache Spark jobs executados no
Google DataProc, análise exploratória com o Google DataLab, Machine
Learning Analysis com o Google ML e visualização de dados no Google Data
Studio.&lt;/p>
&lt;p>Os dados são transportados por meio de um modelo data-driven, onde os
dados foram planejados para streaming, including o ETL (que funciona em
um micro-batch, para permitir a exploração em near-real-time). Estes dados
passam pelo pipeline de dados utilizando o serviço de mensageria do Google
Pub/Sub, em que cada mensagem é serializada utilizando o formato Avro,
reduzindo a carga e permitindo que o transporte seja econômico, rápido e
confiável.&lt;/p>
&lt;h2 id="impacto-e-resultados">Impacto e resultados&lt;/h2>
&lt;p>Tudo isso permitiu à Dotz ter uma melhor estrutura em sua plataforma
analítica, previamente gerenciada em uma grande instância do MS SQL
Server, sendo deslocada para um Data Lake com camadas que permitem a
categorização, governança, qualidade e segurança dos dados.&lt;/p>
&lt;p>Suporte a processos analíticos de dados dos usuários, exploração ágil
e monetização de seus conhecimentos sobre o comportamento dos clientes.&lt;/p></description></item><item><title>Easynvest Data Platform</title><link>https://macunha.me/pt/project/easynvest-data-platform/</link><pubDate>Mon, 03 Jul 2017 00:00:00 +0000</pubDate><guid>https://macunha.me/pt/project/easynvest-data-platform/</guid><description>&lt;h1 id="introdução">Introdução&lt;/h1>
&lt;h2 id="sumário">Sumário&lt;/h2>
&lt;p>Dentro do planejamento anual da Easynvest, um investimento na expansão da
equipe de data &amp;amp; analytics teve como objetivo encurtar a tomada de decisão
e entregar maior qualidade aos clientes por meio de um processo operacional
com baixo custo.&lt;/p>
&lt;p>Dentre os principais objetivos deste projeto, tivemos a automatização de
análise de crédito na aprovação do cadastro de clientes utilizando Machine
Learning, um processo que até então era longo e manual, sendo realizado pelo
back office.&lt;/p>
&lt;p>Seguido de uma melhor oferta de produtos ao cliente, realizando a
categorização de acordo com o perfil de cada cliente, permitindo sugestões
mais atraentes de produtos, estando alinhadas com as preferências pessoais,
assim como de acordo com o perfil de cada investidor (conservador, moderado
ou agressivo).&lt;/p>
&lt;p>Por último, mas não menos importante, a detecção inteligente de lavagem de
dinheiro gerando relatórios para as autoridades responsáveis.&lt;/p>
&lt;h2 id="problemática">Problemática&lt;/h2>
&lt;p>Entretanto, houve limitações nas ferramentas de dados, principalmente devido ao
fato de seram softwares proprietários (com licenças limitadas) e projetados para
uso em data centers. Além disso, o banco de dados analítico foi modelado
para modelos tradicionais de Business Intelligence (OLAP, etc), tornando o
processo de tomada de decisão pesado, devido à quantidade exigente de interações
durante o ETL.&lt;/p>
&lt;p>Anteriormente para um cliente ser aprovado, o processo levava de 10 a 15 dias.
Para que todas as informações necessárias fossem coletadas, tendo uma perspectiva
completa do perfil, includindo análises de crédito. Após coletar as informações o
back office gerava uma pontuação na análise interna de crédito.&lt;/p>
&lt;p>Sendo que, na maioria dos casos, o cliente não era notificado sobre atualizações
referentes ao processo e não recebia feedback ao fim (caso recusado), a menos que
fosse explicitamente solicitado (contatando o suporte via chat ou e-mail, por
exemplo) o que tornava o processo demorado e custoso. Sem contar as inúmeras
quantidades de clientes perdidos para a concorrência durante esta longa espera.&lt;/p>
&lt;h1 id="solução">Solução&lt;/h1>
&lt;h2 id="implementação-técnica">Implementação Técnica&lt;/h2>
&lt;p>Para tornar isso possível, construímos uma implementação híbrida em nuvem usando AWS
componentes baseados em nuvem (principalmente AWS S3, EMR e ECS), para extender a
capacidade do data center, implementando um ecossistema Hadoop cloud-first
(substituindo os componentes de software proprietário por open-source equivalentes).
Dando à Easynvest a possibilidade de crescer seu Data Lake exponencialmente.&lt;/p>
&lt;p>O design do Data Lake foi robusto, visando lidar com a execução pesada de processos
analíticos através de modelos de Machine Learning, com suporte para data quality,
governança de metadados, segurança da informação e self-service de dados (os
proprietários dos dados poderiam compartilhar seus dados com consumidores de outras
áreas da empresa, permitindo o auto-serviço de seus dados analíticos).&lt;/p>
&lt;p>Um Chatbot também foi utilizado para reduzir a carga operacional no ambiente, sendo
responsável pela manutenção e atualização dos componentes de infra-estrutura.
Desde o acionamento de deployments até a geração de chaves de criptografia on-demand
para segurança e governança da plataforma de dados. Implementado com Errbot em Python
interagindo com Slack.&lt;/p>
&lt;p>Indo além, implementamos as melhores práticas de DevOps, tendo Jenkins como
ferramenta para CI/CD dos componentes desenvolvidos junto com Ansible para
Gerenciamento da Configuração.&lt;/p>
&lt;h2 id="impacto-e-resultados">Impacto e resultados&lt;/h2>
&lt;p>Graças à utilização de camadas no Data Lake e a implementação de pipelines de dados,
conseguimos reduzir o tempo de ingestão dos dados em 78%, incluindo metadados e
catálogo de dados, além de automatizar grande parte do trabalho que antes era feito
manualmente durante a ingestão.&lt;/p>
&lt;p>Assim, trazendo resultados positivos, principalmente durante a aprovação de novos
registros de usuários, de ~10 dias para aproximadamente 1 dia. Tornando também
a plataforma de dados mais democrática, fornecendo informações relevantes que
facilita a análise de outras áreas da companhia como risco (análise de crédito) e
suporte (atendimento), sem ter que abrir mão da segurança.&lt;/p></description></item><item><title>Movida Rent A DevOps</title><link>https://macunha.me/pt/project/movida-rent-a-devops/</link><pubDate>Tue, 07 Feb 2017 00:00:00 +0000</pubDate><guid>https://macunha.me/pt/project/movida-rent-a-devops/</guid><description>&lt;h1 id="introdução">Introdução&lt;/h1>
&lt;h2 id="sumário">Sumário&lt;/h2>
&lt;p>JSL Holdings Ltda, detentora da Julio Simões Logistica (maior player LATAM
de logística) comprou a Movida Rent a Car em 2013 para expandir o portfólio
e abrir novas oportunidades no mercado de locação e venda de veículos mercados.&lt;/p>
&lt;p>A JSL investiu em torno de R$ 1,8 bilhão na Movida, e multiplicou a receita
em 21 vezes de R$ 58m para R$ 1,2b, em 3 anos. Com base nestes resultados
de sucesso, a JSL Holdings Ltd planejou um IPO para a Movida.&lt;/p>
&lt;h2 id="problemática">Problemática&lt;/h2>
&lt;p>Para ser negociada em bolsa, a Movida teria que passar por uma auditoria.
Porém a solução de software não estava de acordo com algumas normas de
segurança.&lt;/p>
&lt;p>O projeto começou em Dezembro de 2016, planejando a implementação de um
processo de automátizado de publicação de software adotando DevOps em seu
data center. Com os seguintes objetivos:&lt;/p>
&lt;ol>
&lt;li>&lt;strong>segurança&lt;/strong>; nenhuma pessoa deveria acessar os servidores Linux. e&lt;/li>
&lt;li>&lt;strong>produtividade&lt;/strong>; liberando recursos mais rapidamente para encurtar o
time-to-market de novas features.&lt;/li>
&lt;/ol>
&lt;h1 id="solução">Solução&lt;/h1>
&lt;h2 id="implementação-técnica">Implementação Técnica&lt;/h2>
&lt;p>Nosso primeiro objetivo era implementar o pipeline suportando CI/CD utilizando
Jenkins, responsável por empacotar novas funcionalidades, criar um deployment
e implementá-lo no data center. Além do deployment em produção, o
pipeline também apoiou a criação de ambientes &lt;em>on-demand&lt;/em> para homologação de
recursos e coleta de feedback dos usuários.&lt;/p>
&lt;p>Para ter um ciclo de aprovação mais rápido e controlado, migramos o servidor
Git para dentro do data center. Através desta ação nós reduziu em 5 minutos
(62%) do tempo total de deployment e aumentamos o controle sobre os acessos
em seus repositórios.&lt;/p>
&lt;p>A implementação de CI/CD utilizou Jenkins Pipeline para CI/CD, GitLab com
autenticação LDAP, e Ansible como Configuration Manager. Um deployment
completo leva cerca de 2 minutos desde o &lt;code>git push&lt;/code> até o código estar em
produção.&lt;/p>
&lt;p>Além da implantação de um pipeline para CI/CD, também trabalhamos em uma
estratégia de self-service para a execução de jobs sem acesso direto por SSH
aos servidores. Rundeck entrou em cena, com configurações de RBAC e
visibilidade sobre o histórico de jobs executados.&lt;/p>
&lt;h2 id="impacto-e-resultados">Impacto e resultados&lt;/h2>
&lt;p>Movida foi auditada em Janeiro 2017, no final de Janeiro de 2017 eles
receberam a aprovação.&lt;/p>
&lt;p>Duas semanas depois, em fevereiro de 2017, a Movida lançou seu IPO,
marcado como o primeiro IPO brasileiro de 2017. Abrindo seu capital
no dia 8 de Fevereiro de 2017, levantando cerca de R$ 645M.&lt;/p></description></item><item><title>Nextel Digital Release</title><link>https://macunha.me/pt/project/nextel-digital-release/</link><pubDate>Wed, 30 Nov 2016 00:00:00 +0000</pubDate><guid>https://macunha.me/pt/project/nextel-digital-release/</guid><description>&lt;h1 id="introdução">Introdução&lt;/h1>
&lt;h2 id="sumário">Sumário&lt;/h2>
&lt;p>A Nextel planejou desenvolver uma aplicação móvel para reduzir seus
custos operacionais com call centers e reduzir o &lt;em>contact rate&lt;/em>.
&amp;ldquo;Nextel Digital&amp;rdquo; foi o nome dado ao projeto responsável por lançar
esta aplicação.&lt;/p>
&lt;p>Com o tempo, o projeto &amp;ldquo;Nextel Digital&amp;rdquo; absorveu mais objetivos, como
melhorar a user experience, e se tornou um novo produto chamado &amp;ldquo;Happy&amp;rdquo;,
uma operadora de telefonia digital. Nextel Happy permite que os usuários
gerenciem seus planos e dados completamente pelo aplicativo, desde a
ativação do seu SIM até a gestão de plano familiar.&lt;/p>
&lt;p>Este projeto ajudou a Nextel a aumentar sua base de clientes, melhorando
a experiência dos usuários, e diminuir os custos operacionais (em 16%).&lt;/p>
&lt;h2 id="problemática">Problemática&lt;/h2>
&lt;p>A equipe executiva da Nextel Brasil decidiu trabalhar com terceirização
no desenvolvimento deste produto para absorver conhecimento das empresas
e para complementar suas capacidades internas. Assim como trazer
diferentes perspectivas em jogo, melhorando o processo criativo.&lt;/p>
&lt;p>Nossa equipe assumiu a responsabilidade de arquitetar e implementar a
infraestrutura de núvem garantindo alta disponibilidade, resiliência e
consistência do software.&lt;/p>
&lt;p>Assim como assumimos a responsabilidade de sincronizar os dados entre o
data center da Nextel e a nuvem. Movendo com segurança uma quantia grande
em GB de dados relacionados à consumo para a núvem diariamente, sem perda
ou duplicação dos dados.&lt;/p>
&lt;h1 id="solução">Solução&lt;/h1>
&lt;h2 id="implementação-técnica">Implementação técnica&lt;/h2>
&lt;p>k
Escolhemos o GlusterFS para garantir a consistência, instalado entre o
data center da Nextel e a AWS, sincronizando os dados de usuários
(ex.: consumo do plano de dados, minutos de chamada).
A equipe de operações da Nextel IT alimentava o GlusterFS diretamente
com os dados de torres telefônicas, permitindo processamento em
near-real-time.&lt;/p>
&lt;p>Assim que os dados estavam disponíveis no volume montado em instâncias
na AWS, a implementação em Celery entra em jogo. No centro da arquitetura,
o Celery (implementado em Python 3) usando Redis como message broker,
executa jobs assíncronos para inspecionar eventos no GlusterFS.&lt;/p>
&lt;p>Uma vez que o Celery detecta um novo arquivo disponível ele analisa o
conteúdo e inicia um multipart upload para o AWS S3, em seguida compara
os checksums para garantir a consistência (e retenta em caso de
inconsistência).&lt;/p>
&lt;p>Após chegar ao AWS S3, o evento do objeto aciona uma função AWS Lambda
para analisar o conteúdo e indexá-lo no Elasticsearch, sendo
posteriormente servido aos clientes através de uma API REST.&lt;/p>
&lt;p>Toda o design da infrastrutura foi planejada para &lt;a href="https://www.oreilly.com/radar/an-introduction-to-immutable-infrastructure/" target="_blank" rel="noopener">ser imutável&lt;/a>,
facilitando a evolução e confiabilidade, tendo Ansible como Configuration
Manager e AWS CloudFormation como provisionador na nuvem. Em apenas
alguns minutos é possível recriar todo o ecossistema, com esforço mínimo.&lt;/p>
&lt;h2 id="impacto-e-resultados">Impacto e resultados&lt;/h2>
&lt;p>Todo o processo de disponibilização dos dados de uma torre celular que
tomava em torno de 1 dia foi reduzido para 5 minutos.
Como consequência, o tempo de duração das chamadas nos call center caiu
~56%, devido à alternativa de self-service fornecida no aplicativo.&lt;/p>
&lt;p>Além disso, os usuários podem gerenciar seu histórico de chamadas e
planejar o consumo diretamente pelo celular, com atualizações em
near-real-time. Proporcionano um feedback consistente e interativo.&lt;/p></description></item></channel></rss>