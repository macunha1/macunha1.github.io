<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts | It's me, Macunha!</title><link>https://macunha.me/pt/post/</link><atom:link href="https://macunha.me/pt/post/index.xml" rel="self" type="application/rss+xml"/><description>Posts</description><generator>Wowchemy (https://wowchemy.com)</generator><language>pt-br</language><copyright>© 2021 Matheus Cunha</copyright><lastBuildDate>Thu, 21 May 2020 23:00:57 +0200</lastBuildDate><image><url>https://macunha.me/media/icon_hu176de0364afaeda8922c372b574c3cbf_6946_512x512_fill_lanczos_center_2.png</url><title>Posts</title><link>https://macunha.me/pt/post/</link></image><item><title>Quickstart: Apache Spark no Kubernetes</title><link>https://macunha.me/pt/post/2020/05/quickstart-apache-spark-no-kubernetes/</link><pubDate>Thu, 21 May 2020 23:00:57 +0200</pubDate><guid>https://macunha.me/pt/post/2020/05/quickstart-apache-spark-no-kubernetes/</guid><description>&lt;h1 id="introduction">Introduction&lt;/h1>
&lt;h2 id="apache-spark-operator-para-kubernetes">Apache Spark Operator para Kubernetes&lt;/h2>
&lt;p>Desde o seu lançamento em 2014 pela Google, o Kubernetes tem ganhado
muita popularidade junto com o próprio Docker e desde 2016 passou a
ser o &lt;em>de facto Container orchestrator&lt;/em>, estabelecido como um padrão
de mercado. Possuindo versões gerenciadas em &lt;strong>todas&lt;/strong> as &lt;em>major
Clouds&lt;/em>&lt;a href="https://cloud.google.com/kubernetes-engine/" target="_blank" rel="noopener">[1]&lt;/a>
&lt;a href="https://aws.amazon.com/eks/" target="_blank" rel="noopener">[2]&lt;/a>
&lt;a href="https://docs.microsoft.com/en-us/azure/aks/" target="_blank" rel="noopener">[3]&lt;/a> (inclusive
&lt;a href="https://www.digitalocean.com/products/kubernetes/" target="_blank" rel="noopener">Digital Ocean&lt;/a> e
&lt;a href="https://www.alibabacloud.com/product/kubernetes" target="_blank" rel="noopener">Alibaba&lt;/a>).&lt;/p>
&lt;p>Toda essa popularidade tem atraído novas implementações e &lt;em>use-cases&lt;/em>
para o orquestrador, dentre eles a execução de &lt;a href="https://kubernetes.io/docs/tutorials/stateful-application/" target="_blank" rel="noopener">Stateful
applications&lt;/a>
incluindo &lt;a href="https://vitess.io/zh/docs/get-started/kubernetes/" target="_blank" rel="noopener">bancos de dados em containers&lt;/a>.&lt;/p>
&lt;p>Qual seria a necessidade de ter um banco de dados orquestrado? Ótima
pergunta. Por hoje, vamos focar na utilização do &lt;a href="https://github.com/GoogleCloudPlatform/spark-on-k8s-operator/blob/master/docs/design.md" target="_blank" rel="noopener">Spark Operator&lt;/a>
para executar &lt;strong>Spark jobs&lt;/strong> em Kubernetes.&lt;/p>
&lt;p>A idéia do Spark Operator &lt;a href="https://github.com/kubernetes/kubernetes/issues/34377" target="_blank" rel="noopener">surgiu&lt;/a>
em 2016, antes disso haviam apenas alguns &lt;em>jeitinhos&lt;/em>, por exemplo:
&lt;a href="https://kubernetes.io/blog/2016/03/using-spark-and-zeppelin-to-process-big-data-on-kubernetes/" target="_blank" rel="noopener">com Apache Zeppelin&lt;/a>
dentro do Kubernetes, ou então, mais refinado ainda &lt;a href="https://github.com/kubernetes/examples/tree/master/staging/spark" target="_blank" rel="noopener">criando o seu
próprio Apache Spark cluster dentro do Kubernetes (exemplo do
repositório oficial do Kubernetes)&lt;/a>
que usaria o &lt;a href="http://spark.apache.org/docs/latest/spark-standalone.html" target="_blank" rel="noopener">Spark Standalone mode&lt;/a>.&lt;/p>
&lt;p>Porém, executar nativamente seria muito mais interessante pois poderia
aproveitar o &lt;a href="https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/" target="_blank" rel="noopener">Kubernetes Scheduler&lt;/a>
para ações relacionadas à alocação dos recursos no cluster, dando mais
elasticidade e uma interface mais simples para gerenciar os workloads
no Apache Spark.&lt;/p>
&lt;p>Considernando esses pontos o &lt;a href="https://issues.apache.org/jira/browse/SPARK-18278" target="_blank" rel="noopener">desenvolvimento do Apache Spark Operator
ganhou atenção&lt;/a>,
foi &lt;em>mergeado&lt;/em> e publicado na &lt;a href="https://spark.apache.org/releases/spark-release-2-3-0.html" target="_blank" rel="noopener">versão do Apache Spark 2.3.0&lt;/a>
em &lt;a href="https://spark.apache.org/news/index.html" target="_blank" rel="noopener">Fevereiro de 2018&lt;/a>.&lt;/p>
&lt;p>Se você estiver interessado em ler mais sobre a proposta do Apache
Spark Operator, existe um &lt;a href="https://docs.google.com/document/d/1_bBzOZ8rKiOSjQg78DXOA3ZBIo_KkDJjqxVuq0yXdew/edit#heading=h.9bhogel14x0y" target="_blank" rel="noopener">design document publicado no Google Docs.&lt;/a>&lt;/p>
&lt;h2 id="por-que-kubernetes">Por que Kubernetes?&lt;/h2>
&lt;p>Como atualmente as empresas estão buscando se &lt;a href="https://www.cio.com/article/3211428/what-is-digital-transformation-a-necessary-disruption.html" target="_blank" rel="noopener">reinventar por meio da
tão falada transformação
digital&lt;/a>
para que possam ter competitividade e, principalmente, sobreviver
diante de um mercado cada vez mais dinâmico, é comum ver abordagens
que incluam Big Data, Inteligência Artificial e Cloud Computing
&lt;a href="https://www.zdnet.com/article/how-to-use-cloud-computing-and-big-data-to-support-digital-transformation/" target="_blank" rel="noopener">[1]&lt;/a>
&lt;a href="https://digitalhealth.london/cloud-big-data-ai-lead-nhs-digital-transformation/" target="_blank" rel="noopener">[2]&lt;/a>
&lt;a href="https://www.ibm.com/blogs/cloud-computing/2018/11/05/guiding-framework-digital-transformation-garage/" target="_blank" rel="noopener">[3]&lt;/a>.&lt;/p>
&lt;p>Para compreender os benefícios de utilizar Cloud ao invés de On-premises no
contexto de Big Data vale a pena ler o artigo &lt;a href="https://databricks.com/blog/2017/05/31/top-5-reasons-for-choosing-s3-over-hdfs.html" target="_blank" rel="noopener">da Databricks&lt;/a>,
que é a empresa &lt;a href="https://www.washingtonpost.com/news/the-switch/wp/2016/06/09/this-is-where-the-real-action-in-artificial-intelligence-takes-place/" target="_blank" rel="noopener">fundada pelos criadores do Apache
Spark&lt;/a>.&lt;/p>
&lt;p>Como nós vemos uma adoção de Cloud Computing generalizada (até por
empresas que teriam condições de bancar o próprio hardware), também
podemos notar que na maiorira dessas implementações de Cloud não
existem clusters de &lt;a href="https://hadoop.apache.org/" target="_blank" rel="noopener">Apache Hadoop&lt;/a>
já que os times de Dados (BI/Data Science/Analytics) optam cada vez
mais por utilizar ferramentas como &lt;a href="https://cloud.google.com/bigquery/" target="_blank" rel="noopener">Google BigQuery&lt;/a>
ou &lt;a href="https://aws.amazon.com/redshift/" target="_blank" rel="noopener">AWS Redshift&lt;/a>. Portanto, não faz sentido
subir um Hadoop apenas para utilizar o &lt;a href="https://hortonworks.com/apache/yarn/" target="_blank" rel="noopener">YARN&lt;/a>
como gerenciador os recursos.&lt;/p>
&lt;p>Uma alternativa é a utilização de provisionadores de clusters Hadoop
como o &lt;a href="https://cloud.google.com/dataproc" target="_blank" rel="noopener">Google DataProc&lt;/a> ou o &lt;a href="https://aws.amazon.com/emr/" target="_blank" rel="noopener">AWS
EMR&lt;/a> para a criação de clusters efêmeros.
Apenas para nomear algumas opções.&lt;/p>
&lt;p>Para entender melhor o design do Spark Operator, recomendo a leitura
da documentação gerada pela equipe da &lt;a href="https://github.com/GoogleCloudPlatform/spark-on-k8s-operator/blob/master/docs/design.md#the-crd-controller" target="_blank" rel="noopener">GCP no
GitHub&lt;/a>.&lt;/p>
&lt;h1 id="hora-de-meter-a-mão-na-massa">Hora de meter a mão na massa!&lt;/h1>
&lt;h2 id="aquecendo-o-motor">Aquecendo o motor&lt;/h2>
&lt;p>Agora que toda a palavra já foi passada, vamos ao hands-on para
mostrar a coisa acontecendo. Para isso, vamos usar:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.docker.com/" target="_blank" rel="noopener">Docker&lt;/a> como motor de container no
Kubernetes, e construção da imagem &lt;a href="https://docs.docker.com/install/" target="_blank" rel="noopener">(link para
instalação)&lt;/a>;&lt;/li>
&lt;li>Minikube &lt;a href="https://kubernetes.io/docs/tasks/tools/install-minikube/" target="_blank" rel="noopener">(link para instalação)&lt;/a>
para facilitar o provisionamento do Kubernetes (sim, será uma
execução local);&lt;/li>
&lt;li>Para interagir com a API do Kubernetes é preciso ter o &lt;code>kubectl&lt;/code>
instalado. &lt;a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/" target="_blank" rel="noopener">Se você não tiver, siga as instruções aqui&lt;/a>.&lt;/li>
&lt;li>uma versão compilada do Apache Spark que seja maior do que a
2.3.0.
&lt;ol>
&lt;li>você pode tanto compilar &lt;a href="https://github.com/apache/spark" target="_blank" rel="noopener">do código fonte&lt;/a>,
que vai tomar &lt;em>algumas horas&lt;/em> até terminar, quanto&lt;/li>
&lt;li>fazer o download de uma versão compilada &lt;a href="https://spark.apache.org/downloads.html" target="_blank" rel="noopener">aqui&lt;/a>
(recomendado).&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;p>Assim que o Apache estiver descompactado, vamos adicionar o
caminho no PATH para facilitar a execução:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">export PATH&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>PATH&lt;span style="color:#e6db74">}&lt;/span>:/path/to/apache-spark-X.Y.Z/bin
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="criando-o-cluster-com-minikube">Criando o &amp;ldquo;cluster&amp;rdquo; com Minikube&lt;/h2>
&lt;p>Agora, para ter um Kubernetes vamos iniciar um &lt;code>minikube&lt;/code> com o
propósito de rodar um dos exemplos disponíveis no &lt;a href="https://github.com/apache/spark/blob/master/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala" target="_blank" rel="noopener">repositório do Spark&lt;/a>
chamado &lt;code>SparkPi&lt;/code> apenas para demonstração.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">minikube start --cpus&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --memory&lt;span style="color:#f92672">=&lt;/span>4g
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="buildando-a-imagem-docker">Buildando a imagem Docker&lt;/h2>
&lt;p>Vamos utilizar o Docker daemon do Minikube para não depender de um
registry externo (e só gerar lixo na VM, facilitando a limpeza
depois). Para isso, o minikube tem um wrapper que facilita a nossa
vida:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">eval &lt;span style="color:#66d9ef">$(&lt;/span>minikube docker-env&lt;span style="color:#66d9ef">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Após ter configurado as variáveis de ambiente para o Docker daemon,
vamos precisar de uma imagem Docker para executar os jobs.
Existe um &lt;a href="https://github.com/apache/spark/blob/master/bin/docker-image-tool.sh" target="_blank" rel="noopener">shell script no repositório do Spark&lt;/a>
para ajudar com isso. Considerando que o &lt;code>PATH&lt;/code> está configurado
corretamente, basta executar:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">docker-image-tool.sh -m -t latest build
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;em>Obs.:&lt;/em> O parâmetro &lt;code>-m&lt;/code> aqui indica que é um build para o minikube.&lt;/p>
&lt;p>Vamos pegar a via expressa para executar o SparkPi, usando o mesmo
comando que seria utilizado para um cluster Spark &lt;a href="https://spark.apache.org/docs/latest/submitting-applications.html" target="_blank" rel="noopener">spark-submit&lt;/a>.&lt;/p>
&lt;p>Porém, o Spark Operator dá suporte a definição de jobs no &amp;ldquo;dialeto do
Kubernetes&amp;rdquo; usando &lt;a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/" target="_blank" rel="noopener">CRD&lt;/a>,
&lt;a href="https://github.com/GoogleCloudPlatform/spark-on-k8s-operator/tree/master/examples" target="_blank" rel="noopener">aqui tem alguns exemplos&lt;/a> - para depois.&lt;/p>
&lt;h2 id="fire-in-the-hole">Fire in the hole!&lt;/h2>
&lt;p>Cuidado com o vão entre a versão do Scala e a plataforma quando
estiver parametrizando o job:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">spark-submit --master k8s://https://&lt;span style="color:#66d9ef">$(&lt;/span>minikube ip&lt;span style="color:#66d9ef">)&lt;/span>:8443 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --deploy-mode cluster &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --name spark-pi &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --class org.apache.spark.examples.SparkPi &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --conf spark.executor.instances&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --executor-memory 1024m &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --conf spark.kubernetes.container.image&lt;span style="color:#f92672">=&lt;/span>spark:latest &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> local:///opt/spark/examples/jars/spark-examples_2.11-X.Y.Z.jar &lt;span style="color:#75715e"># aqui&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>O que temos de novidade é:&lt;/p>
&lt;ul>
&lt;li>&lt;code>--master&lt;/code>: Aceita o prefixo &lt;code>k8s://&lt;/code> na URL, para o endpoint da
API do Kubernetes, exposta pelo commando &lt;code>https://$(minikube ip):8443&lt;/code>.
Aliás, se estiver interessado, isso é um &lt;a href="https://www.gnu.org/software/bash/manual/html_node/Command-Substitution.html" target="_blank" rel="noopener">command substitution no
shell&lt;/a>;&lt;/li>
&lt;li>&lt;code>--conf spark.kubernetes.container.image=&lt;/code>: Configuração para a
imagem Docker que será executada no Kubernetes.&lt;/li>
&lt;/ul>
&lt;p>Com o output:&lt;/p>
&lt;pre>&lt;code>...
19/08/22 11:59:09 INFO LoggingPodStatusWatcherImpl: State changed,
new state: pod name: spark-pi-1566485909677-driver namespace: default
labels: spark-app-selector -&amp;gt; spark-20477e803e7648a59e9bcd37394f7f60,
spark-role -&amp;gt; driver pod uid: c789c4d2-27c4-45ce-ba10-539940cccb8d
creation time: 2019-08-22T14:58:30Z service account name: default
volumes: spark-local-dir-1, spark-conf-volume, default-token-tj7jn
node name: minikube start time: 2019-08-22T14:58:30Z container
images: spark:docker phase: Succeeded status:
[ContainerStatus(containerID=docker://e044d944d2ebee2855cd2b993c62025d
6406258ef247648a5902bf6ac09801cc, image=spark:docker,
imageID=docker://sha256:86649110778a10aa5d6997d1e3d556b35454e9657978f3
a87de32c21787ff82f, lastState=ContainerState(running=null,
terminated=null, waiting=null, additionalProperties={}),
name=spark-kubernetes-driver, ready=false, restartCount=0,
state=ContainerState(running=null,
terminated=ContainerStateTerminated(containerID=docker://e044d944d2ebe
e2855cd2b993c62025d6406258ef247648a5902bf6ac09801cc, exitCode=0,
finishedAt=2019-08-22T14:59:08Z, message=null, reason=Completed,
signal=null, startedAt=2019-08-22T14:58:32Z,
additionalProperties={}), waiting=null, additionalProperties={}),
additionalProperties={})]
19/08/22 11:59:09 INFO LoggingPodStatusWatcherImpl: Container final
statuses: Container name: spark-kubernetes-driver Container image:
spark:docker Container state: Terminated Exit code: 0
&lt;/code>&lt;/pre>&lt;p>Para ver o resultado do job (e toda a execução), podemos mandar um
&lt;code>kubectl logs&lt;/code> passando o nome do pod do driver como parâmetro:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kubectl logs &lt;span style="color:#66d9ef">$(&lt;/span>kubectl get pods | grep &lt;span style="color:#e6db74">&amp;#39;spark-pi.*-driver&amp;#39;&lt;/span>&lt;span style="color:#66d9ef">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Que traz o output (algumas entradas foram omitidas), parecido com:&lt;/p>
&lt;pre>&lt;code>...
19/08/22 14:59:08 INFO TaskSetManager: Finished task 1.0 in stage 0.0
(TID 1) in 52 ms on 172.17.0.7 (executor 1) (2/2)
19/08/22 14:59:08 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose
tasks have all completed, from pool19/08/22 14:59:08 INFO
DAGScheduler: ResultStage 0 (reduce at SparkPi.scala:38) finished in
0.957 s
19/08/22 14:59:08 INFO DAGScheduler: Job 0 finished: reduce at
SparkPi.scala:38, took 1.040608 s Pi is roughly 3.138915694578473
19/08/22 14:59:08 INFO SparkUI: Stopped Spark web UI at
http://spark-pi-1566485909677-driver-svc.default.svc:4040
19/08/22 14:59:08 INFO KubernetesClusterSchedulerBackend: Shutting
down all executors
19/08/22 14:59:08 INFO
KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint: Asking
each executor to shut down
19/08/22 14:59:08 WARN ExecutorPodsWatchSnapshotSource: Kubernetes
client has been closed (this is expected if the application is
shutting down.)
19/08/22 14:59:08 INFO MapOutputTrackerMasterEndpoint:
MapOutputTrackerMasterEndpoint stopped!
19/08/22 14:59:08 INFO MemoryStore: MemoryStore cleared
19/08/22 14:59:08 INFO BlockManager: BlockManager stopped
19/08/22 14:59:08 INFO BlockManagerMaster: BlockManagerMaster stopped
19/08/22 14:59:08 INFO
OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:
OutputCommitCoordinator stopped!
19/08/22 14:59:08 INFO SparkContext: Successfully stopped SparkContext
19/08/22 14:59:08 INFO ShutdownHookManager: Shutdown hook called
19/08/22 14:59:08 INFO ShutdownHookManager: Deleting directory
/tmp/spark-aeadc6ba-36aa-4b7e-8c74-53aa48c3c9b2
19/08/22 14:59:08 INFO ShutdownHookManager: Deleting directory
/var/data/spark-084e8326-c8ce-4042-a2ed-75c1eb80414a/spark-ef8117bf-90
d0-4a0d-9cab-f36a7bb18910
&lt;/code>&lt;/pre>&lt;p>O resultado aparece no stdout:&lt;/p>
&lt;pre>&lt;code>19/08/22 14:59:08 INFO DAGScheduler: Job 0 finished: reduce at
SparkPi.scala:38, took 1.040608 s Pi is roughly 3.138915694578473
&lt;/code>&lt;/pre>&lt;p>Para finalizar, vamos deletar a VM que o Minikube gera, para limpar o
ambiente (a menos que você queira continuar brincando com ele):&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">minikube delete
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="últimas-palavras">Últimas palavras&lt;/h2>
&lt;p>Espero ter dispertado bastante curiosidade e algumas ideias para
ir além no desenvolvimento dos seus workloads de Big Data.
Se tiver alguma dúvida ou sugestão, não deixe de postar na seção de
comentários.&lt;/p></description></item><item><title>DevOps: Os benefícios da implementação</title><link>https://macunha.me/pt/post/2019/01/devops-benefits/</link><pubDate>Fri, 11 Jan 2019 22:00:00 +0000</pubDate><guid>https://macunha.me/pt/post/2019/01/devops-benefits/</guid><description>&lt;h1 id="introdução">Introdução&lt;/h1>
&lt;p>Principais benefícios que uma companhia geralmente espera e encontra na adoção
da cultura:&lt;/p>
&lt;h2 id="releases-mais-rápidos-e-baratos">Releases mais rápidos e baratos&lt;/h2>
&lt;p>Como os releases serão frequentes, as entregas acabam sendo pequenas. Entregas
pequenas trazem o benefício de aumentar a velocidade no ciclo de desenvolvimento
(entregando sempre)&lt;/p>
&lt;h2 id="suporte-operacional-melhorado-com-ajustes-rápidos">Suporte operacional melhorado com ajustes rápidos&lt;/h2>
&lt;p>Caso haja alguma falha durante a entrega, o impacto é menor pois a quantidade de
modificações é pequena, assim como o rollback é rápido.&lt;/p>
&lt;h2 id="melhor-time-to-market-ttm">Melhor time to market (TTM)&lt;/h2>
&lt;p>O software será entregue muito mais cedo, quando ainda for um MVP. Os clientes
serão integrados como parte do processo de desenvolvimento, trazendo insights e
feedbacks para o time. Permitindo assim que haja uma velocidade maior de
lançamento no mercado.&lt;/p>
&lt;h2 id="produtos-de-qualidade-superior">Produtos de qualidade superior&lt;/h2>
&lt;p>Como foi falado antes, falhar cedo impede que defeitos sejam entregues em
produção&lt;/p>
&lt;p>Assim como:&lt;/p>
&lt;ul>
&lt;li>Menor volume de defeitos no produto como um todo;&lt;/li>
&lt;li>Aumento na frequência de novas features e releases;&lt;/li>
&lt;li>Processos de desenvolvimento apropriados nos times, incluindo automação.&lt;/li>
&lt;/ul>
&lt;h1 id="agora-que-entendemos-o-por-que-vamos-ao-como">Agora que entendemos o POR QUE, vamos ao COMO&lt;/h1>
&lt;h2 id="continuous-releases-integration-delivery-deployment">Continuous releases (integration, delivery, deployment)&lt;/h2>
&lt;p>Geralmente segue uma abordagem de versionamento de código (por meio do Git)
utilizando branches específicas para cada ambiente.&lt;/p>
&lt;h2 id="continuous-integration">Continuous integration&lt;/h2>
&lt;p>Execução automática dos testes unitários, integrados e também de qualidade de
código na branch, para garantir que não houve quebra de funcionamento do pedaço
modificado do código.&lt;/p>
&lt;h2 id="continuous-delivery">Continuous delivery&lt;/h2>
&lt;p>Empacotamento do software que está testado e aprovado, para deixar ele em algum
lugar que seja possível fazer um deploy posteriormente. Exemplos são libs
entregues em repositórios para ser integradas no código durante o próximo update
e deploy de código&lt;/p>
&lt;h2 id="continuous-deployment">Continuous deployment&lt;/h2>
&lt;p>Após conseguir completar todos os passos anteriores, é possível fazer deploy
automatizado direto nos ambientes, quando o time estiver com mais confiança em
relação às ferramentas que testam, assim como com a questão de assumir riscos e
entender que existe a possibilidade de falhar em ambientes de teste, sem
preocupações.&lt;/p>
&lt;h2 id="configuration-eou-infrastructure-as-code">Configuration (e/ou Infrastructure) as code&lt;/h2>
&lt;p>Para que seja possível testar o software com assertividade, e entender que ele
irá transitar entre os ambientes sem mudar de comportamento, é de extrema
importância que as configurações sejam também código. Isso permite que as
configurações sejam também versionadas, acompanhando o código. Garantindo também
uma uniformidade entre os ambientes, que possibilita:&lt;/p>
&lt;ul>
&lt;li>Redução nos custos de manutenção, tendo um ponto único para olhar e entender o
funcionamento do sistema;&lt;/li>
&lt;li>Facilidade para recriar a infraestrutura, caso seja necessário mover tudo para
outro lugar, isso pode acontecer com poucas interações manuais;&lt;/li>
&lt;li>Permite que haja code review da infraestrutura e das configurações, que por
consequência traz uma cultura de colaboração no desenvolvimento,
compartilhamento do conhecimento e aumenta a democratização da infra;&lt;/li>
&lt;li>Documentação como código, ajudando novos membros do time a terem um warm up
mais rápido.&lt;/li>
&lt;/ul>
&lt;p>Esses pontos foram bem estressados pelo time da Heroku, e deram origem ao famoso
paper: &lt;a href="https://12factor.net/" target="_blank" rel="noopener">The Twelve-Factor App&lt;/a>. Uma leitura muito boa
para a explicação dos benefícios sobre gerência de configuração.&lt;/p>
&lt;h2 id="monitoramento-e-self-healing">Monitoramento e self-healing&lt;/h2>
&lt;p>Ao fim de todo o processo de entrega, o software deverá estar sendo monitorado,
para que não seja necessário esperar um report externo de falhas, garantindo que
as ações sejam pró-ativas e não reativas.&lt;/p>
&lt;p>Garantir que o monitoramento esteja maduro, também nos permite automatizar a
parte de reação aos alertas, criando um sistema de self-healing em que ações
(scripts) são executados para corrigir possíveis falhas conhecidas na
infraestrutura. Permitindo assim que todos possam dormir tranquilamente de
noite, sem ter que ficar preocupado com o plantão tocar e ter que ler
documentação de madrugada. (Se você já teve experiência com isso, sabe com
certeza o quanto é ruim).&lt;/p>
&lt;p>Escalando assim apenas os casos que forem extremas exceções (erros não
conhecidos/esperados) no processo para o plantonista atuar, garantindo uma maior
saúde na operação.&lt;/p>
&lt;h2 id="automação-de-processos">Automação de processos&lt;/h2>
&lt;p>Todo o processo que estiver causando Muda é alvo de automação, para que as
pessoas possam trabalhar com mais agilidade. Bons exemplos de processos que
costumam ser automatizados são:&lt;/p>
&lt;ul>
&lt;li>Deployment;&lt;/li>
&lt;li>Self-healing (resiliência do sistema em resposta às anomalias);&lt;/li>
&lt;li>Renovação de Certificados;&lt;/li>
&lt;li>Execução de testes (unitários, de integração, funcionais, etc);&lt;/li>
&lt;li>Monitoramento (com auto-discovery);&lt;/li>
&lt;li>Governança de usuários;&lt;/li>
&lt;/ul>
&lt;h1 id="devops-toolchainhttpsenwikipediaorgwikidevops_toolchain">&lt;a href="https://en.wikipedia.org/wiki/DevOps_toolchain" target="_blank" rel="noopener">DevOps toolchain&lt;/a>&lt;/h1>
&lt;p>Uma combinação de ferramentas para facilitar a manutenção e operação do sistema,
seguindo o seguinte fluxo:&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://macunha.me/img/content/devops-lifecycle.png" alt="Ciclo de desenvolvimento utilizando DevOps" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;blockquote>
&lt;p>Obs.: Qualquer semelhança com o PDCA é mera certeza.&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>&lt;strong>Plan&lt;/strong>: Fase de planejamento do projeto, em que são coletados os feedbacks
para levantamento de requisitos, e criação do backlog;&lt;/li>
&lt;li>&lt;strong>Create&lt;/strong>: Criação de um entregável (para validar uma hipótese), como um MVP;&lt;/li>
&lt;li>&lt;strong>Verify&lt;/strong>: Passar o entregável para a fase de testes;&lt;/li>
&lt;li>&lt;strong>Package:&lt;/strong> Empacotar o entregável (build) para conseguir colocar ele em
algum ambiente de testes;&lt;/li>
&lt;li>&lt;strong>Release&lt;/strong>: Fazer o deployment do entregável empacotado;&lt;/li>
&lt;li>&lt;strong>Configure&lt;/strong>: Realizar a configuração do entregável no ambiente de testes,
tentando chegar o mais próximo possível do twelve-factor app.&lt;/li>
&lt;li>&lt;strong>Monitor&lt;/strong>: Após fazer o deployment no ambiente, acompanhar as métricas de
negócio e infraestrutura, para garantir que está tudo funcionando conforme o
esperado.&lt;/li>
&lt;/ul>
&lt;h1 id="conclusão">Conclusão&lt;/h1>
&lt;p>Durante a implementação dessas técnicas é possível observar melhoras no processo
de desenvolvimento, os ganhos mais notáveis são:&lt;/p>
&lt;ul>
&lt;li>Melhoria no engajamento do time;&lt;/li>
&lt;li>Compartilhamento de conhecimento;&lt;/li>
&lt;li>Redução de bottlenecks;&lt;/li>
&lt;li>Mais tempo livre para realizar trabalho que realmente importa (agrega valor
para a experiência do usuário ou gera impacto);&lt;/li>
&lt;li>Maior confiança ao entregar software.&lt;/li>
&lt;/ul></description></item><item><title>DevOps: Genesis</title><link>https://macunha.me/pt/post/2019/01/devops-genesis/</link><pubDate>Fri, 11 Jan 2019 21:00:00 +0000</pubDate><guid>https://macunha.me/pt/post/2019/01/devops-genesis/</guid><description>&lt;h1 id="introdução">Introdução&lt;/h1>
&lt;p>&lt;em>First of all, it’s all about Agile.&lt;/em>&lt;/p>
&lt;p>A metodologia DevOps foi criada utilizando os conceitos dos métodos Ágeis, para
entregar um grande valor durante o processo de desenvolvimento de software,
automatizando o release de features com pipelines, para conseguir provar
hipóteses mais rápido e assim se adaptar mais rápido às mudanças por meio de uma
abordagem “fail-fast”. Essas mudanças são mais culturais do que técnicas,
portanto é comum dizer que DevOps é cultura.&lt;/p>
&lt;p>A implementação de DevOps acontece por meio da automação de processos, tendo
muito forte dentro dessa implementação a reengenharia de processos da empresa. A
implementação da parte técnica é simples e fácil se comparada com a mudança de
comportamento das pessoas. Portanto, é bastante confuso o papel que um
“Engenheiro/Analista DevOps” desempenharia, no meio dessa confusão, existem
muitos SysAdmins e Analistas de Infra assumindo o papel de “DevOps”.&lt;/p>
&lt;h2 id="first-things-first-lean-é-a-base-do-agile">First things first, Lean é a base do Agile&lt;/h2>
&lt;p>A realidade não é tão feliz quanto parece. Depois da segunda guerra mundial, o
Japão estava destruído e com poucos recursos, após ter perdido a guerra. Com uma
quantia limitada de recursos, o país precisou se reinventar e sobreviver após
uma época de forte depressão, durante essa época dois caras ficaram famosos pelo
trabalho realizado dentro de uma empresa, que mais tarde teve o nome dedicado ao
modelo que foi criado.&lt;/p>
&lt;p>Esses caras eram Eiji Toyoda e Taiichi Ohno, que trabalhavam para a Toyota Motor
Corporation. Foram os fundadores do modelo de produção Toyota, também conhecido
como Toyotismo.&lt;/p>
&lt;h2 id="toyota-deu-origem-ao-lean">Toyota deu origem ao Lean&lt;/h2>
&lt;p>Lean é uma metodologia que ensina a otimizar os processos da empresa;
end-to-end, para dar mais atenção às tarefas que &lt;strong>entregam valor&lt;/strong> ao
consumidor final, incentivando ao máximo a remoção de bottlenecks no processo,
assim como a análise de tarefas que são desperdício (definidas pelos 3M) para
que sejam identificadas e removidas.&lt;/p>
&lt;p>Essas tarefas consideradas desperdício são classificadas como 3M dentro do Lean
que representam: &lt;em>Muda, Mura, e Muri&lt;/em>. Outro ponto importante a destacar no
processo é a utilização do método nomeado Kaizen (continuous improvement), com
foco em melhorar continuamente buscando atingir um nível de excelência em
qualidade.&lt;/p>
&lt;p>A qualidade faz parte da cultura japonesa, pois existe a crença de que um
produto de qualidade traz o cliente de volta, mesmo que os produtos demorem mais
para estragar, os clientes serão fiéis a eles, pois terão uma boa experiência.
Antes mesmo de falarmos sobre user experience, eles já estavam pensando nisso.&lt;/p>
&lt;h2 id="kaizen">Kaizen&lt;/h2>
&lt;p>Um mindset que ajuda a olhar para cada parte do processo exclusivamente e pensar
nas melhorias, envolvendo as pessoas que fazem parte do processo, assim
incentiva que haja a inclusão dessas pessoas nas decisões de mudança, já que:&lt;/p>
&lt;ul>
&lt;li>Fica muito mais fácil de aceitar uma mudança quando ela não é imposta
(top-down);&lt;/li>
&lt;li>Há uma absorção maior das mudanças pelas pessoas, quando elas são incluídas
no processo;&lt;/li>
&lt;li>As pessoas que são incluídas no processo trazem as suas preocupações e
sugestões, que contribuem positivamente com a evolução da mudança, tornando as
ideias propostas mais robustas devido ao incentivo em relação à contribuição.&lt;/li>
&lt;/ul>
&lt;p>O processo de definição das melhorias por meio de Kaizen acontece (normalmente)
na seguinte ordem:&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://cdn-images-1.medium.com/max/600/1*N8KelcHbixESci5Y0JQoYA.png" alt="círculo PDCA" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;ol>
&lt;li>Definir objetivos com base em dados;&lt;/li>
&lt;li>Revisar o estado atual e desenvolver um plano de melhoria;&lt;/li>
&lt;li>Implementar a melhoria;&lt;/li>
&lt;li>Revisar a implementação e corrigir o que não funciona;&lt;/li>
&lt;li>Reportar os resultados e determinar os itens a serem monitorados.&lt;/li>
&lt;/ol>
&lt;p>Esse processo é bastante chamado de &lt;strong>PDCA: Plain-Do-Control-Act&lt;/strong>, que se
resume em:&lt;/p>
&lt;ul>
&lt;li>Plan (desenvolver a hipótese);&lt;/li>
&lt;li>Do (executar um experimento);&lt;/li>
&lt;li>Check (validar os resultados);&lt;/li>
&lt;li>Act (refinar o experimento e recomeçar).&lt;/li>
&lt;/ul>
&lt;h1 id="3m-muda-mura-muri">3M: Muda, Mura, Muri&lt;/h1>
&lt;h2 id="muda-desperdício">Muda (desperdício)&lt;/h2>
&lt;p>Qualquer atividade que consuma tempo sem agregar valor ao consumidor final.
Como por exemplo:&lt;/p>
&lt;ul>
&lt;li>produção em excesso;&lt;/li>
&lt;li>tempo parado (ocioso) no processo;&lt;/li>
&lt;li>defeito nos produtos.&lt;/li>
&lt;/ul>
&lt;p>É importante lembrar que existem níveis diferentes de Muda que podem ser ou não
removidos com rapidez, e a classificação depende do tempo para remoção.&lt;/p>
&lt;p>Um exemplo de Muda mais demorado é a descontinuação de um software legado que
acaba tendo ciclos mais longos de release, causando tempo ocioso nos times,
muitas vezes uma rotina de testes longa e manual.&lt;/p>
&lt;h2 id="mura-desigualdade">Mura (desigualdade)&lt;/h2>
&lt;p>Atividades que são muito variáveis e imprevisíveis, gerando resultados
diferentes em todas as execuções. Por exemplo: a execução de tarefas que não
foram bem planejadas e acabam chegando com prazos rígidos. São executadas na
correria, gerando um desgaste, desespero, e ainda por cima, ao terminar deixam
as pessoas que executaram essas tarefas esperando (seja um feedback, ou então a
confirmação de que está finalizado).&lt;/p>
&lt;h2 id="muri-sobrecarga">Muri (sobrecarga)&lt;/h2>
&lt;p>Exigir que as pessoas (ou os equipamentos) trabalhem além do limite, para
atingir algum tipo de meta ou expectativa, gerando cansaço e consequentemente
falhas durante o processo. Essas falhas são geralmente erros humanos causados
pelo cansaço durante o trabalho excessivo.&lt;/p>
&lt;h1 id="voltando-ao-agile">Voltando ao Agile…&lt;/h1>
&lt;p>No ano 2000 um grupo de 17 pessoas se encontrou em um resort em Oregon para
conversar sobre ideias que poderiam melhorar o fluxo de desenvolvimento de
software. Depois de um ano de amadurecimento das ideias, essas pessoas se
encontraram de novo e publicaram as ideias, que hoje conhecemos como: Agile
Manifesto.&lt;/p>
&lt;p>Os principais pontos são:&lt;/p>
&lt;ul>
&lt;li>Individuals and interactions over processes and tools&lt;/li>
&lt;li>Working software over comprehensive documentation&lt;/li>
&lt;li>Customer collaboration over contract negotiation&lt;/li>
&lt;li>Responding to change over following a plan&lt;/li>
&lt;/ul>
&lt;p>Vou me restringuir a explicação desses pontos com o ponto de vista DevOps, para
não fugir (mais) do tema.&lt;/p>
&lt;h2 id="individuals-and-interactions">Individuals and interactions&lt;/h2>
&lt;p>&lt;em>over processes and tools&lt;/em>&lt;/p>
&lt;p>As pessoas devem receber o kit de ferramentas (tooling) apropriado para
trabalhar e então serem empoderados para realizar seu trabalho. As interações
entre pessoas é extremamente incentivada, para o compartilhamento de
conhecimento e também para facilitar o fluxo criativo dentro dos times de
desenvolvimento.&lt;/p>
&lt;p>Um excelente exemplo de interação incentivada por meio de DevOps é o hábito de
code review. Considerando que pequenas partes do software serão iteradas e
aprovadas no pipeline passando por diferentes ambientes, de maneira automática,
o melhor jeito de prevenir defeitos é por meio de code review.&lt;/p>
&lt;p>Esse hábito traz benefício como:&lt;/p>
&lt;ul>
&lt;li>Compartilhamento de conhecimento no time;&lt;/li>
&lt;li>Observação do problema em diferentes pontos de vista;&lt;/li>
&lt;li>Engajamento no time;&lt;/li>
&lt;li>Redução no número de bugs.&lt;/li>
&lt;/ul>
&lt;h2 id="working-software">Working software&lt;/h2>
&lt;p>&lt;em>over comprehensive documentation&lt;/em>&lt;/p>
&lt;p>Aqui existe um trick na questão do working software, um software que funciona
não é “compilou, tá funcionando”. O software que funciona é o que atende aos
requisitos do usuário; i.e. o software que resolve o problema e as dores do
usuário.&lt;/p>
&lt;p>Como o mercado é muito dinâmico, e evolui com grande velocidade, muitas vezes
durante o projeto de desenvolvimento de software os requisitos mudam devido a
fatores externos. Portanto, sabendo que não é possível prever todos os fatores,
muitas gambiarras são feitas no meio do caminho e documentadas, para que o
usuário final aprenda a lidar com as falhas, e executar os workarounds,
gastando mais esforço do que seria necessário para realizar as tarefas por meio
do software.&lt;/p>
&lt;blockquote>
&lt;p>Entregar frequentemente software funcionando, de poucas semanas a poucos
meses, com preferência à menor escala de tempo&lt;/p>
&lt;/blockquote>
&lt;p>Incentivando assim que hajam deployments tanto quanto o possível, para que as
falhas aconteçam o mais cedo possível, permitindo assim que o impacto delas seja
bem menor.&lt;/p>
&lt;h1 id="fail-fast">Fail-fast!&lt;/h1>
&lt;p>As falhas são compreendidas e incentivadas, pois faz parte do mindset entender
que:&lt;/p>
&lt;ul>
&lt;li>Só erra quem faz;&lt;/li>
&lt;li>Falhar é o melhor jeito de aprender e evoluir;&lt;/li>
&lt;li>Shit happens.&lt;/li>
&lt;/ul>
&lt;p>Nada como citar a Lei de Murphy para melhor contextualizar&lt;/p>
&lt;blockquote>
&lt;p>&amp;ldquo;Se algo pode dar errado, dará.&amp;rdquo;&lt;/p>
&lt;/blockquote>
&lt;p>Portanto é melhor que as falhas ocorram cedo, enquanto o custo de correção ainda
é baixo. Falhar em um ambiente controlado de testes, permite que a correção seja
muito mais rápida (e barata) do que seria caso a correção acontecesse já em
produção.&lt;/p>
&lt;p>Para que essa abordagem tenha sucesso, existe a premissa de que os ambientes
sejam cópias de produção, ou pelo menos que seja o mais próximo possível. Do
contrário, haverão mudanças de comportamento no software entre os ambientes,
inviabilizando o ambiente de testes.&lt;/p>
&lt;p>Caso os ambientes sejam divergentes, a promoção de bugs para produção será muito
frequente, causando falhas tarde, que são falhas caras.&lt;/p>
&lt;h2 id="customer-collaboration">Customer collaboration&lt;/h2>
&lt;p>&lt;em>over contract negotiation&lt;/em>&lt;/p>
&lt;p>Também é possível que haja um má levantamento de requisitos durante o início do
projeto, pois muitas vezes o próprio cliente/usuário não conseguiu prever todas
as funcionalidades necessárias.&lt;/p>
&lt;p>Podemos descrever essa situação como:&lt;/p>
&lt;ul>
&lt;li>Do ponto A é possível ver apenas o ponto B;&lt;/li>
&lt;li>Do ponto B é possível ver o ponto C;&lt;/li>
&lt;/ul>
&lt;p>Portanto há um grande incentivo para que o software seja entregue em partes,
continuamente. Colhendo assim os feedbacks do usuário sobre os próximos passos,
seguindo os conceitos de prototipação evolutiva, que foram muito divulgados por
meio do livro &lt;em>The Lean Startup&lt;/em>.&lt;/p>
&lt;p>Esse ponto faz muito contraste com o anterior, em relação à entrega contínua
(continuous release), para que seja possível apresentar o protótipo e evoluir
ele ao longo do projeto.&lt;/p>
&lt;p>&lt;em>Saiba quem é o seu cliente/consumidor/usuário&lt;/em>, e para quem você está fazendo o
software, pois esse é o único jeito de conseguir entregar valor para esse
cliente. Parte importante do processo de desenvolvimento de software é ser
empático com os problemas do usuário, e entender de verdade qual é o problema a
ser resolvido, e o resultado causado pelo impacto no desenvolvimento do software
(geração do valor para o usuário).&lt;/p>
&lt;h2 id="responding-to-change">Responding to change&lt;/h2>
&lt;p>&lt;em>over following a plan&lt;/em>&lt;/p>
&lt;p>Fazer um redesign dos requisitos durante o projeto é parte crucial para o
sucesso do projeto. Será o único jeito de conseguir trazer para a mesa todos os
problemas do usuário, e criar a melhor solução para todos esses problemas, pois
só o usuário sabe dos reais problemas que ele enfrenta no dia-a-dia lidando com
o software.&lt;/p>
&lt;p>Com a entrega contínua de software junto com o monitoramento dos resultados, o
processo de coleta dos feedbacks fica muito mais simples e rápido.&lt;/p>
&lt;h1 id="devops-devops-devops">DevOps, DevOps, DevOps&lt;/h1>
&lt;p>Com a divulgação da palavra DevOps, existe muita gente falando sobre DevOps por
aí. Existindo muita divergência no que é falado, e criando uma confusão grande
sobre o tema. Acaba sendo muito comum se deparar com diferentes interpretações
sobre &lt;strong>o que é DevOps&lt;/strong>. Existe muito eufemismo na área, e gourmetização em
cima do LinkedIn, com muitos SysAdmins por aí se dizendo DevOps, pois aprenderam
a codar shell script dentro do Python.&lt;/p>
&lt;p>Tá afim de continuar lendo? &lt;a href="https://macunha.me/pt/post/2019/01/devops-benefits/">Dá uma olhada nos benefícios de implementar DevOps.&lt;/a>&lt;/p></description></item></channel></rss>