[{"authors":["admin"],"categories":null,"content":"Ol√°!\nEu sou Matheus Cunha (ou apenas Macunha), um Engenheiro de Sistemas focado em DevOps e Engenharia de Dados.\nTenho experi√™ncia em arquitetura de sistemas descentralizados e altamente dispon√≠veis, utilizando n√∫vem p√∫blica ou privada. Trabalhei como consultor em diversas empresas, ajudando-as a ser mais future-proof e competitivas em um ambiente altamente mut√°vel.\nSempre procuro maneiras de melhorar, aprender mais e ir mais longe. Se voc√™ tiver alguma dica, por favor me conte\nTamb√©m sou amante de tecnologia open-source com skill em Linux, que escreve c√≥digos em:\n Java; Python; Go; JavaScript (Node.js); e as vezes Lua ou Rust.  Utilizando os seguintes databases:\n PostgreSQL (para dados relacionais); InfluxDB (incluindo a stack TICK) para time-series; Elasticsearch (incluindo ELK e EBK) para logging e busca; Hadoop (com HDFS, S3 ou Google Cloud Storage) para data warehousing; Kafka como message broker; and Redis para caching e dados ef√™meros (as vezes como message broker tamb√©m).  Monitorando a infrastrutura com Prometheus sendo apoiado pela InfluxData TICK stack (InfluxDB + Kapacitor na maior parte das vezes). Ansible junto com Terraform para fazer infraestrutura como c√≥digo e de prefer√™ncia imut√°vel, rodando tamb√©m Docker em produ√ß√£o dentro do Kubernetes.\nLan√ßei projetos nas principais n√∫vens: AWS, Azure e GCP, assim como ambientes multi-cloud e n√∫vem h√≠brida com servidores on-premises.\nüòÑ\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"pt","lastmod":1589871935,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://macunha.me/pt/author/matheus-cunha/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/pt/author/matheus-cunha/","section":"authors","summary":"Ol√°!\nEu sou Matheus Cunha (ou apenas Macunha), um Engenheiro de Sistemas focado em DevOps e Engenharia de Dados.\nTenho experi√™ncia em arquitetura de sistemas descentralizados e altamente dispon√≠veis, utilizando n√∫vem p√∫blica ou privada.","tags":null,"title":"Matheus Cunha","type":"authors"},{"authors":null,"categories":["DevOps","Agile Manifesto"],"content":"Introdu√ß√£o Principais benef√≠cios que uma companhia geralmente espera e encontra na ado√ß√£o da cultura:\nReleases mais r√°pidos e baratos Como os releases ser√£o frequentes, as entregas acabam sendo pequenas. Entregas pequenas trazem o benef√≠cio de aumentar a velocidade no ciclo de desenvolvimento (entregando sempre)\nSuporte operacional melhorado com ajustes r√°pidos Caso haja alguma falha durante a entrega, o impacto √© menor pois a quantidade de modifica√ß√µes √© pequena, assim como o rollback √© r√°pido.\nMelhor time to market (TTM) O software ser√° entregue muito mais cedo, quando ainda for um MVP. Os clientes ser√£o integrados como parte do processo de desenvolvimento, trazendo insights e feedbacks para o time. Permitindo assim que haja uma velocidade maior de lan√ßamento no mercado.\nProdutos de qualidade superior Como foi falado antes, falhar cedo impede que defeitos sejam entregues em produ√ß√£o\nAssim como:\n Menor volume de defeitos no produto como um todo; Aumento na frequ√™ncia de novas features e releases; Processos de desenvolvimento apropriados nos times, incluindo automa√ß√£o.  Agora que entendemos o POR QUE, vamos ao COMO Continuous releases (integration, delivery, deployment) Geralmente segue uma abordagem de versionamento de c√≥digo (por meio do Git) utilizando branches espec√≠ficas para cada ambiente.\nContinuous integration Execu√ß√£o autom√°tica dos testes unit√°rios, integrados e tamb√©m de qualidade de c√≥digo na branch, para garantir que n√£o houve quebra de funcionamento do peda√ßo modificado do c√≥digo.\nContinuous delivery Empacotamento do software que est√° testado e aprovado, para deixar ele em algum lugar que seja poss√≠vel fazer um deploy posteriormente. Exemplos s√£o libs entregues em reposit√≥rios para ser integradas no c√≥digo durante o pr√≥ximo update e deploy de c√≥digo\nContinuous deployment Ap√≥s conseguir completar todos os passos anteriores, √© poss√≠vel fazer deploy automatizado direto nos ambientes, quando o time estiver com mais confian√ßa em rela√ß√£o √†s ferramentas que testam, assim como com a quest√£o de assumir riscos e entender que existe a possibilidade de falhar em ambientes de teste, sem preocupa√ß√µes.\nConfiguration (e/ou Infrastructure) as code Para que seja poss√≠vel testar o software com assertividade, e entender que ele ir√° transitar entre os ambientes sem mudar de comportamento, √© de extrema import√¢ncia que as configura√ß√µes sejam tamb√©m c√≥digo. Isso permite que as configura√ß√µes sejam tamb√©m versionadas, acompanhando o c√≥digo. Garantindo tamb√©m uma uniformidade entre os ambientes, que possibilita:\n Redu√ß√£o nos custos de manuten√ß√£o, tendo um ponto √∫nico para olhar e entender o funcionamento do sistema; Facilidade para recriar a infraestrutura, caso seja necess√°rio mover tudo para outro lugar, isso pode acontecer com poucas intera√ß√µes manuais; Permite que haja code review da infraestrutura e das configura√ß√µes, que por consequ√™ncia traz uma cultura de colabora√ß√£o no desenvolvimento, compartilhamento do conhecimento e aumenta a democratiza√ß√£o da infra; Documenta√ß√£o como c√≥digo, ajudando novos membros do time a terem um warm up mais r√°pido.  Esses pontos foram bem estressados pelo time da Heroku, e deram origem ao famoso paper: The Twelve-Factor App. Uma leitura muito boa para a explica√ß√£o dos benef√≠cios sobre ger√™ncia de configura√ß√£o.\nMonitoramento e self-healing Ao fim de todo o processo de entrega, o software dever√° estar sendo monitorado, para que n√£o seja necess√°rio esperar um report externo de falhas, garantindo que as a√ß√µes sejam pr√≥-ativas e n√£o reativas.\nGarantir que o monitoramento esteja maduro, tamb√©m nos permite automatizar a parte de rea√ß√£o aos alertas, criando um sistema de self-healing em que a√ß√µes (scripts) s√£o executados para corrigir poss√≠veis falhas conhecidas na infraestrutura. Permitindo assim que todos possam dormir tranquilamente de noite, sem ter que ficar preocupado com o plant√£o tocar e ter que ler documenta√ß√£o de madrugada. (Se voc√™ j√° teve experi√™ncia com isso, sabe com certeza o quanto √© ruim).\nEscalando assim apenas os casos que forem extremas exce√ß√µes (erros n√£o conhecidos/esperados) no processo para o plantonista atuar, garantindo uma maior sa√∫de na opera√ß√£o.\nAutoma√ß√£o de processos Todo o processo que estiver causando Muda √© alvo de automa√ß√£o, para que as pessoas possam trabalhar com mais agilidade. Bons exemplos de processos que costumam ser automatizados s√£o:\n Deployment; Self-healing (resili√™ncia do sistema em resposta √†s anomalias); Renova√ß√£o de Certificados; Execu√ß√£o de testes (unit√°rios, de integra√ß√£o, funcionais, etc); Monitoramento (com auto-discovery); Governan√ßa de usu√°rios;  DevOps toolchain Uma combina√ß√£o de ferramentas para facilitar a manuten√ß√£o e opera√ß√£o do sistema, seguindo o seguinte fluxo:\n Obs.: Qualquer semelhan√ßa com o PDCA √© mera certeza.\n  Plan: Fase de planejamento do projeto, em que s√£o coletados os feedbacks para levantamento de requisitos, e cria√ß√£o do backlog; Create: Cria√ß√£o de um entreg√°vel (para validar uma hip√≥tese), como um MVP; Verify: Passar o entreg√°vel para a fase de testes; Package: Empacotar o entreg√°vel (build) para conseguir colocar ele em algum ambiente de testes; Release: Fazer o deployment do entreg√°vel empacotado; Configure: Realizar a configura√ß√£o do entreg√°vel no ambiente de testes, tentando chegar o mais pr√≥ximo poss√≠vel do twelve-factor app. Monitor: Ap√≥s fazer o deployment no ambiente, acompanhar as m√©tricas de neg√≥cio e infraestrutura, para garantir que est√° tudo funcionando conforme o esperado.  Conclus√£o Durante a implementa√ß√£o dessas t√©cnicas √© poss√≠vel observar melhoras no processo de desenvolvimento, os ganhos mais not√°veis s√£o:\n Melhoria no engajamento do time; Compartilhamento de conhecimento; Redu√ß√£o de bottlenecks; Mais tempo livre para realizar trabalho que realmente importa (agrega valor para a experi√™ncia do usu√°rio ou gera impacto); Maior confian√ßa ao entregar software.  ","date":1547247600,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1589823897,"objectID":"234c851ba757bb2bbbda260c3e11abe3","permalink":"https://macunha.me/pt/post/2019/01/devops-benefits/","publishdate":"2019-01-11T23:00:00Z","relpermalink":"/pt/post/2019/01/devops-benefits/","section":"post","summary":"Introdu√ß√£o Principais benef√≠cios que uma companhia geralmente espera e encontra na ado√ß√£o da cultura:\nReleases mais r√°pidos e baratos Como os releases ser√£o frequentes, as entregas acabam sendo pequenas.","tags":["devops","culture","agile","lean"],"title":"DevOps: Os benef√≠cios da implementa√ß√£o","type":"post"},{"authors":null,"categories":["DevOps","Agile Manifesto"],"content":"Introdu√ß√£o First of all, it‚Äôs all about Agile.\nA metodologia DevOps foi criada utilizando os conceitos dos m√©todos √Ågeis, para entregar um grande valor durante o processo de desenvolvimento de software, automatizando o release de features com pipelines, para conseguir provar hip√≥teses mais r√°pido e assim se adaptar mais r√°pido √†s mudan√ßas por meio de uma abordagem ‚Äúfail-fast‚Äù. Essas mudan√ßas s√£o mais culturais do que t√©cnicas, portanto √© comum dizer que DevOps √© cultura.\nA implementa√ß√£o de DevOps acontece por meio da automa√ß√£o de processos, tendo muito forte dentro dessa implementa√ß√£o a reengenharia de processos da empresa. A implementa√ß√£o da parte t√©cnica √© simples e f√°cil se comparada com a mudan√ßa de comportamento das pessoas. Portanto, √© bastante confuso o papel que um ‚ÄúEngenheiro/Analista DevOps‚Äù desempenharia, no meio dessa confus√£o, existem muitos SysAdmins e Analistas de Infra assumindo o papel de ‚ÄúDevOps‚Äù.\nFirst things first, Lean √© a base do Agile A realidade n√£o √© t√£o feliz quanto parece. Depois da segunda guerra mundial, o Jap√£o estava destru√≠do e com poucos recursos, ap√≥s ter perdido a guerra. Com uma quantia limitada de recursos, o pa√≠s precisou se reinventar e sobreviver ap√≥s uma √©poca de forte depress√£o, durante essa √©poca dois caras ficaram famosos pelo trabalho realizado dentro de uma empresa, que mais tarde teve o nome dedicado ao modelo que foi criado.\nEsses caras eram Eiji Toyoda e Taiichi Ohno, que trabalhavam para a Toyota Motor Corporation. Foram os fundadores do modelo de produ√ß√£o Toyota, tamb√©m conhecido como Toyotismo.\nToyota deu origem ao Lean Lean √© uma metodologia que ensina a otimizar os processos da empresa; end-to-end, para dar mais aten√ß√£o √†s tarefas que entregam valor ao consumidor final, incentivando ao m√°ximo a remo√ß√£o de bottlenecks no processo, assim como a an√°lise de tarefas que s√£o desperd√≠cio (definidas pelos 3M) para que sejam identificadas e removidas.\nEssas tarefas consideradas desperd√≠cio s√£o classificadas como 3M dentro do Lean que representam: Muda, Mura, e Muri. Outro ponto importante a destacar no processo √© a utiliza√ß√£o do m√©todo nomeado Kaizen (continuous improvement), com foco em melhorar continuamente buscando atingir um n√≠vel de excel√™ncia em qualidade.\nA qualidade faz parte da cultura japonesa, pois existe a cren√ßa de que um produto de qualidade traz o cliente de volta, mesmo que os produtos demorem mais para estragar, os clientes ser√£o fi√©is a eles, pois ter√£o uma boa experi√™ncia. Antes mesmo de falarmos sobre user experience, eles j√° estavam pensando nisso.\nKaizen Um mindset que ajuda a olhar para cada parte do processo exclusivamente e pensar nas melhorias, envolvendo as pessoas que fazem parte do processo, assim incentiva que haja a inclus√£o dessas pessoas nas decis√µes de mudan√ßa, j√° que:\n Fica muito mais f√°cil de aceitar uma mudan√ßa quando ela n√£o √© imposta (top-down); H√° uma absor√ß√£o maior das mudan√ßas pelas pessoas, quando elas s√£o inclu√≠das no processo; As pessoas que s√£o inclu√≠das no processo trazem as suas preocupa√ß√µes e sugest√µes, que contribuem positivamente com a evolu√ß√£o da mudan√ßa, tornando a ideia mais robusta.  O processo de defini√ß√£o das melhorias por meio de Kaizen acontece (normalmente) na seguinte ordem:\n Definir objetivos com base em dados; Revisar o estado atual e desenvolver um plano de melhoria; Implementar a melhoria; Revisar a implementa√ß√£o e corrigir o que n√£o funciona; Reportar os resultados e determinar os itens a serem monitorados.  Esse processo √© bastante chamado de PDCA: Plain-Do-Control-Act, que se resume em:\n Plan (desenvolver a hip√≥tese); Do (executar um experimento); Check (validar os resultados); Act (refinar o experimento e recome√ßar).  3M: Muda, Mura, Muri Muda (desperd√≠cio) Qualquer atividade que consuma tempo sem agregar valor ao consumidor final. Como por exemplo:\n produ√ß√£o em excesso; tempo parado (ocioso) no processo; defeito nos produtos.  √â importante lembrar que existem n√≠veis diferentes de Muda que podem ser ou n√£o removidos com rapidez, e a classifica√ß√£o depende do tempo para remo√ß√£o.\nUm exemplo de Muda mais demorado √© a descontinua√ß√£o de um software legado que acaba tendo ciclos mais longos de release, causando tempo ocioso nos times, muitas vezes uma rotina de testes longa e manual.\nMura (desigualdade) Atividades que s√£o muito vari√°veis e imprevis√≠veis, gerando resultados diferentes em todas as execu√ß√µes. Por exemplo: a execu√ß√£o de tarefas que n√£o foram bem planejadas e acabam chegando com prazos r√≠gidos. S√£o executadas na correria, gerando um desgaste, desespero, e ainda por cima, ao terminar deixam as pessoas que executaram essas tarefas esperando (seja um feedback, ou ent√£o a confirma√ß√£o de que est√° finalizado).\nMuri (sobrecarga) Exigir que as pessoas (ou os equipamentos) trabalhem al√©m do limite, para atingir algum tipo de meta ou expectativa, gerando cansa√ßo e consequentemente falhas durante o processo. Essas falhas s√£o geralmente erros humanos causados pelo cansa√ßo durante o trabalho excessivo.\nVoltando ao Agile‚Ä¶ No ano 2000 um grupo de 17 pessoas se encontrou em um resort em Oregon para conversar sobre ideias que poderiam melhorar o fluxo de desenvolvimento de software. Depois de um ano de amadurecimento das ideias, essas pessoas se encontraram de novo e publicaram as ideias, que hoje conhecemos como: Agile Manifesto.\nOs principais pontos s√£o:\n Individuals and interactions over processes and tools Working software over comprehensive documentation Customer collaboration over contract negotiation Responding to change over following a plan  Vou me restringuir a explica√ß√£o desses pontos com o ponto de vista DevOps, para n√£o fugir (mais) do tema.\nIndividuals and interactions over processes and tools\nAs pessoas devem receber o kit de ferramentas (tooling) apropriado para trabalhar e ent√£o serem empoderados para realizar seu trabalho. As intera√ß√µes entre pessoas √© extremamente incentivada, para o compartilhamento de conhecimento e tamb√©m para facilitar o fluxo criativo dentro dos times de desenvolvimento.\nUm excelente exemplo de intera√ß√£o incentivada por meio de DevOps √© o h√°bito de code review. Considerando que pequenas partes do software ser√£o iteradas e aprovadas no pipeline passando por diferentes ambientes, de maneira autom√°tica, o melhor jeito de prevenir defeitos √© por meio de code review.\nEsse h√°bito traz benef√≠cio como:\n Compartilhamento de conhecimento no time; Observa√ß√£o do problema em diferentes pontos de vista; Engajamento no time; Redu√ß√£o no n√∫mero de bugs.  Working software over comprehensive documentation\nAqui existe um trick na quest√£o do working software, um software que funciona n√£o √© ‚Äúcompilou, t√° funcionando‚Äù. O software que funciona √© o que atende aos requisitos do usu√°rio; i.e. o software que resolve o problema e as dores do usu√°rio.\nComo o mercado √© muito din√¢mico, e evolui com grande velocidade, muitas vezes durante o projeto de desenvolvimento de software os requisitos mudam devido a fatores externos. Portanto, sabendo que n√£o √© poss√≠vel prever todos os fatores, muitas gambiarras s√£o feitas no meio do caminho e documentadas, para que o usu√°rio final aprenda a lidar com as falhas, e executar os workarounds, gastando mais esfor√ßo do que seria necess√°rio para realizar as tarefas por meio do software.\n Entregar frequentemente software funcionando, de poucas semanas a poucos meses, com prefer√™ncia √† menor escala de tempo\n Incentivando assim que hajam deployments tanto quanto o poss√≠vel, para que as falhas aconte√ßam o mais cedo poss√≠vel, permitindo assim que o impacto delas seja bem menor.\nFail-fast! As falhas s√£o compreendidas e incentivadas, pois faz parte do mindset entender que:\n S√≥ erra quem faz; Falhas acontecem.  Portanto √© melhor que as falhas ocorram cedo, enquanto o custo de corre√ß√£o ainda √© baixo. Falhar em um ambiente controlado de testes, permite que a corre√ß√£o seja muito mais r√°pida (e barata) do que seria caso a corre√ß√£o acontecesse j√° em produ√ß√£o.\nPara que essa abordagem tenha sucesso, existe a premissa de que os ambientes sejam c√≥pias de produ√ß√£o, ou pelo menos que seja o mais pr√≥ximo poss√≠vel. Do contr√°rio, haver√£o mudan√ßas de comportamento no software entre os ambientes, inviabilizando o ambiente de testes.\nCaso os ambientes sejam divergentes, a promo√ß√£o de bugs para produ√ß√£o ser√° muito frequente, causando falhas tarde, que s√£o falhas caras.\nCustomer collaboration over contract negotiation\nTamb√©m √© poss√≠vel que haja um m√° levantamento de requisitos durante o in√≠cio do projeto, pois muitas vezes o pr√≥prio cliente/usu√°rio n√£o conseguiu prever todas as funcionalidades necess√°rias.\nPodemos descrever essa situa√ß√£o como:\n Do ponto A √© poss√≠vel ver apenas o ponto B; Do ponto B √© poss√≠vel ver o ponto C;  Portanto h√° um grande incentivo para que o software seja entregue em partes, continuamente. Colhendo assim os feedbacks do usu√°rio sobre os pr√≥ximos passos, seguindo os conceitos de prototipa√ß√£o evolutiva, que foram muito divulgados por meio do livro The Lean Startup.\nEsse ponto faz muito contraste com o anterior, em rela√ß√£o √† entrega cont√≠nua (continuous release), para que seja poss√≠vel apresentar o prot√≥tipo e evoluir ele ao longo do projeto.\nSaiba quem √© o seu cliente/consumidor/usu√°rio, e para quem voc√™ est√° fazendo o software, pois esse √© o √∫nico jeito de conseguir entregar valor para esse cliente. Parte importante do processo de desenvolvimento de software √© ser emp√°tico com os problemas do usu√°rio, e entender de verdade qual √© o problema a ser resolvido, e o resultado causado pelo impacto no desenvolvimento do software (gera√ß√£o do valor para o usu√°rio).\nResponding to change over following a plan\nFazer um redesign dos requisitos durante o projeto √© parte crucial para o sucesso do projeto. Ser√° o √∫nico jeito de conseguir trazer para a mesa todos os problemas do usu√°rio, e criar a melhor solu√ß√£o para todos esses problemas, pois s√≥ o usu√°rio sabe dos reais problemas que ele enfrenta no dia-a-dia lidando com o software.\nCom a entrega cont√≠nua de software junto com o monitoramento dos resultados, o processo de coleta dos feedbacks fica muito mais simples e r√°pido.\nDevOps, DevOps, DevOps Com a divulga√ß√£o da palavra DevOps, existe muita gente falando sobre DevOps por a√≠. Existindo muita diverg√™ncia no que √© falado, e criando uma confus√£o grande sobre o tema. Acaba sendo muito comum se deparar com diferentes interpreta√ß√µes sobre o que √© DevOps. Existe muito eufemismo na √°rea, e gourmetiza√ß√£o em cima do LinkedIn, com muitos SysAdmins por a√≠ se dizendo DevOps, pois aprenderam a codar shell script dentro do Python.\nT√° afim de continuar lendo? D√° uma olhada nos benef√≠cios de implementar DevOps.\n","date":1547244000,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1589734215,"objectID":"1ea695d486767aac5f192dfd0ddf47d4","permalink":"https://macunha.me/pt/post/2019/01/devops-genesis/","publishdate":"2019-01-11T22:00:00Z","relpermalink":"/pt/post/2019/01/devops-genesis/","section":"post","summary":"Introdu√ß√£o First of all, it‚Äôs all about Agile.\nA metodologia DevOps foi criada utilizando os conceitos dos m√©todos √Ågeis, para entregar um grande valor durante o processo de desenvolvimento de software, automatizando o release de features com pipelines, para conseguir provar hip√≥teses mais r√°pido e assim se adaptar mais r√°pido √†s mudan√ßas por meio de uma abordagem ‚Äúfail-fast‚Äù.","tags":["devops","culture","agile","lean"],"title":"DevOps: De onde vieram e para onde v√£o","type":"post"},{"authors":null,"categories":null,"content":"Introdu√ß√£o Sum√°rio Dentro do planejamento anual da Easynvest, um investimento na expans√£o da equipe de data \u0026amp; analytics teve como objetivo encurtar a tomada de decis√£o e entregar maior qualidade aos clientes por meio de um processo operacional com baixo custo.\nDentre os principais objetivos deste projeto, tivemos a automatiza√ß√£o de an√°lise de cr√©dito na aprova√ß√£o do cadastro de clientes utilizando Machine Learning, um processo que at√© ent√£o era longo e manual, sendo realizado pelo back office.\nSeguido de uma melhor oferta de produtos ao cliente, realizando a categoriza√ß√£o de acordo com o perfil de cada cliente, permitindo sugest√µes mais atraentes de produtos, estando alinhadas com as prefer√™ncias pessoais, assim como de acordo com o perfil de cada investidor (conservador, moderado ou agressivo).\nPor √∫ltimo, mas n√£o menos importante, a detec√ß√£o inteligente de lavagem de dinheiro gerando relat√≥rios para as autoridades respons√°veis.\nProblem√°tica Entretanto, houve limita√ß√µes nas ferramentas de dados, principalmente devido ao fato de seram softwares propriet√°rios (com licen√ßas limitadas) e projetados para uso em data centers. Al√©m disso, o banco de dados anal√≠tico foi modelado para modelos tradicionais de Business Intelligence (OLAP, etc), tornando o processo de tomada de decis√£o pesado, devido √† quantidade exigente de intera√ß√µes durante o ETL.\nAnteriormente para um cliente ser aprovado, o processo levava de 10 a 15 dias. Para que todas as informa√ß√µes necess√°rias fossem coletadas, tendo uma perspectiva completa do perfil, includindo an√°lises de cr√©dito. Ap√≥s coletar as informa√ß√µes o back office gerava uma pontua√ß√£o na an√°lise interna de cr√©dito.\nSendo que, na maioria dos casos, o cliente n√£o era notificado sobre atualiza√ß√µes referentes ao processo e n√£o recebia feedback ao fim (caso recusado), a menos que fosse explicitamente solicitado (contatando o suporte via chat ou e-mail, por exemplo) o que tornava o processo demorado e custoso. Sem contar as in√∫meras quantidades de clientes perdidos para a concorr√™ncia durante esta longa espera.\nSolu√ß√£o Implementa√ß√£o T√©cnica Para tornar isso poss√≠vel, constru√≠mos uma implementa√ß√£o h√≠brida em nuvem usando AWS componentes baseados em nuvem (principalmente AWS S3, EMR e ECS), para extender a capacidade do data center, implementando um ecossistema Hadoop cloud-first (substituindo os componentes de software propriet√°rio por open-source equivalentes). Dando √† Easynvest a possibilidade de crescer seu Data Lake exponencialmente.\nO design do Data Lake foi robusto, visando lidar com a execu√ß√£o pesada de processos anal√≠ticos atrav√©s de modelos de Machine Learning, com suporte para data quality, governan√ßa de metadados, seguran√ßa da informa√ß√£o e self-service de dados (os propriet√°rios dos dados poderiam compartilhar seus dados com consumidores de outras √°reas da empresa, permitindo o auto-servi√ßo de seus dados anal√≠ticos).\nUm Chatbot tamb√©m foi utilizado para reduzir a carga operacional no ambiente, sendo respons√°vel pela manuten√ß√£o e atualiza√ß√£o dos componentes de infra-estrutura. Desde o acionamento de deployments at√© a gera√ß√£o de chaves de criptografia on-demand para seguran√ßa e governan√ßa da plataforma de dados. Implementado com Errbot em Python interagindo com Slack.\nIndo al√©m, implementamos as melhores pr√°ticas de DevOps, tendo Jenkins como ferramenta para CI/CD dos componentes desenvolvidos junto com Ansible para Gerenciamento da Configura√ß√£o.\nImpacto e resultados Gra√ßas √† utiliza√ß√£o de camadas no Data Lake e a implementa√ß√£o de pipelines de dados, conseguimos reduzir o tempo de ingest√£o dos dados em 78%, incluindo metadados e cat√°logo de dados, al√©m de automatizar grande parte do trabalho que antes era feito manualmente durante a ingest√£o.\nAssim, trazendo resultados positivos, principalmente durante a aprova√ß√£o de novos registros de usu√°rios, de ~10 dias para aproximadamente 1 dia. Tornando tamb√©m a plataforma de dados mais democr√°tica, fornecendo informa√ß√µes relevantes que facilita a an√°lise de outras √°reas da companhia como risco (an√°lise de cr√©dito) e suporte (atendimento), sem ter que abrir m√£o da seguran√ßa.\n","date":1499040000,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1589871935,"objectID":"85d7e13b7fc188beab732ff2f4c83ca7","permalink":"https://macunha.me/pt/project/2017/easynvest-data-platform/","publishdate":"2017-07-03T00:00:00Z","relpermalink":"/pt/project/2017/easynvest-data-platform/","section":"project","summary":"Introdu√ß√£o Sum√°rio Dentro do planejamento anual da Easynvest, um investimento na expans√£o da equipe de data \u0026amp; analytics teve como objetivo encurtar a tomada de decis√£o e entregar maior qualidade aos clientes por meio de um processo operacional com baixo custo.","tags":["data-eng"],"title":"Easynvest Data Platform","type":"project"},{"authors":null,"categories":null,"content":"Introdu√ß√£o Sum√°rio JSL Holdings Ltda, detentora da Julio Sim√µes Logistica (maior player LATAM de log√≠stica) comprou a Movida Rent a Car em 2013 para expandir o portf√≥lio e abrir novas oportunidades no mercado de loca√ß√£o e venda de ve√≠culos mercados.\nA JSL investiu em torno de R$ 1,8 bilh√£o na Movida, e multiplicou a receita em 21 vezes de R$ 58m para R$ 1,2b, em 3 anos. Com base nestes resultados de sucesso, a JSL Holdings Ltd planejou um IPO para a Movida.\nProblem√°tica Para ser negociada em bolsa, a Movida teria que passar por uma auditoria. Por√©m a solu√ß√£o de softwares n√£o estava de acordo com algumas normas de seguran√ßa.\nO projeto come√ßou em Dezembro de 2016, planejando a implementa√ß√£o de um processo de autom√°tizado de publica√ß√£o de software adotando DevOps em seu data center. Com os seguintes objetivos:\n seguran√ßa; nenhuma pessoa deveria acessar os servidores Linux. e produtividade; liberando recursos mais rapidamente para encurtar o time-to-market de novas features.  Solu√ß√£o Implementa√ß√£o T√©cnica Nosso primeiro objetivo era implementar o pipeline suportando CI/CD utilizando Jenkins, respons√°vel por empacotar novas funcionalidades, criar um deployment e implement√°-lo no data center. Al√©m do deployment em produ√ß√£o, o pipeline tamb√©m apoiou a cria√ß√£o de ambientes on-demand para homologa√ß√£o de recursos e coleta de feedback dos usu√°rios.\nPara ter um ciclo de aprova√ß√£o mais r√°pido e controlado, migramos o servidor Git para dentro do data center. Atrav√©s desta a√ß√£o n√≥s reduziu em 5 minutos (62%) do tempo total de deployment e aumentamos o controle sobre os acessos em seus reposit√≥rios.\nA implementa√ß√£o de CI/CD utilizou Jenkins Pipeline para CI/CD, GitLab com autentica√ß√£o LDAP, e Ansible como Configuration Manager. Um deployment completo leva cerca de 2 minutos desde o git push at√© o c√≥digo estar em produ√ß√£o.\nAl√©m do processo de implanta√ß√£o do CI/CD, tamb√©m tivemos que trabalhar em um estrat√©gia de self-service para a execu√ß√£o de jobs sem acesso direto por SSH aos servidores. Rundeck entrou em cena, com configura√ß√µes de RBAC e visibilidade sobre o hist√≥rico de jobs executados.\nImpacto e resultados Movida foi auditada em Janeiro 2017, no final de Janeiro de 2017 eles receberam a aprova√ß√£o.\nDuas semanas depois, em fevereiro de 2017, a Movida lan√ßou seu IPO, marcado como o primeiro IPO brasileiro de 2017. Abrindo seu capital no dia 8 de Fevereiro de 2017, levantando cerca de R$ 645M.\n","date":1486425600,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1589871935,"objectID":"bb268eef80befd26cecdab4785cba57a","permalink":"https://macunha.me/pt/project/2016/movida-rent-a-devops/","publishdate":"2017-02-07T00:00:00Z","relpermalink":"/pt/project/2016/movida-rent-a-devops/","section":"project","summary":"Introdu√ß√£o Sum√°rio JSL Holdings Ltda, detentora da Julio Sim√µes Logistica (maior player LATAM de log√≠stica) comprou a Movida Rent a Car em 2013 para expandir o portf√≥lio e abrir novas oportunidades no mercado de loca√ß√£o e venda de ve√≠culos mercados.","tags":["devops"],"title":"Movida Rent A DevOps","type":"project"},{"authors":null,"categories":null,"content":"Introdu√ß√£o Sum√°rio A Nextel planejou desenvolver uma aplica√ß√£o m√≥vel para reduzir seus custos operacionais com call centers e reduzir o contact rate. \u0026ldquo;Nextel Digital\u0026rdquo; foi o nome dado ao projeto respons√°vel por lan√ßar esta aplica√ß√£o.\nCom o tempo, o projeto \u0026ldquo;Nextel Digital\u0026rdquo; absorveu mais objetivos, como melhorar a user experience, e se tornou um novo produto chamado \u0026ldquo;Happy\u0026rdquo;, uma operadora de telefonia digital. Nextel Happy permite que os usu√°rios gerenciem seus planos e dados completamente pelo aplicativo, desde a ativa√ß√£o do seu SIM at√© a gest√£o de plano familiar.\nEste projeto ajudou a Nextel a aumentar sua base de clientes, melhorando a experi√™ncia dos usu√°rios, e diminuir os custos operacionais (em 16%).\nProblem√°tica A equipe executiva da Nextel Brasil decidiu trabalhar com terceiriza√ß√£o no desenvolvimento deste produto para absorver conhecimento das empresas e para complementar suas capacidades internas. Assim como trazer diferentes perspectivas em jogo, melhorando o processo criativo.\nNossa equipe assumiu a responsabilidade de arquitetar e implementar a infraestrutura de n√∫vem garantindo alta disponibilidade, resili√™ncia e consist√™ncia do software.\nAssim como assumimos a responsabilidade de sincronizar os dados entre o data center da Nextel e a nuvem. Movendo com seguran√ßa uma quantia grande em GB de dados relacionados √† consumo para a n√∫vem diariamente, sem perda ou duplica√ß√£o dos dados.\nSolu√ß√£o Implementa√ß√£o t√©cnica k Escolhemos o GlusterFS para garantir a consist√™ncia, instalado entre o data center da Nextel e a AWS, sincronizando os dados de usu√°rios (ex.: consumo do plano de dados, minutos de chamada). A equipe de opera√ß√µes da Nextel IT alimentava o GlusterFS diretamente com os dados de torres telef√¥nicas, permitindo processamento em near-real-time.\nAssim que os dados estavam dispon√≠veis no volume montado em inst√¢ncias na AWS, a implementa√ß√£o em Celery entra em jogo. No centro da arquitetura, o Celery (implementado em Python 3) usando Redis como message broker, executa jobs ass√≠ncronos para inspecionar eventos no GlusterFS.\nUma vez que o Celery detecta um novo arquivo dispon√≠vel ele analisa o conte√∫do e inicia um multipart upload para o AWS S3, em seguida compara os checksums para garantir a consist√™ncia (e retenta em caso de inconsist√™ncia).\nAp√≥s chegar ao AWS S3, o evento do objeto aciona uma fun√ß√£o AWS Lambda para analisar o conte√∫do e index√°-lo no Elasticsearch, sendo posteriormente servido aos clientes atrav√©s de uma API REST.\nToda o design da infrastrutura foi planejada para ser imut√°vel, facilitando a evolu√ß√£o e confiabilidade, tendo Ansible como Configuration Manager e AWS CloudFormation como provisionador na nuvem. Em apenas alguns minutos √© poss√≠vel recriar todo o ecossistema, com esfor√ßo m√≠nimo.\nImpacto e resultados Todo o processo de disponibiliza√ß√£o dos dados de uma torre celular que tomava em torno de 1 dia foi reduzido para 5 minutos. Como consequ√™ncia, o tempo de dura√ß√£o das chamadas nos call center caiu ~56%, devido √† alternativa de self-service fornecida no aplicativo.\nAl√©m disso, os usu√°rios podem gerenciar seu hist√≥rico de chamadas e planejar o consumo diretamente pelo celular, com atualiza√ß√µes em near-real-time. Proporcionano um feedback consistente e interativo.\n","date":1480464000,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1589871935,"objectID":"833e846000cba1cddc227ac12811391c","permalink":"https://macunha.me/pt/project/2016/nextel-digital-release/","publishdate":"2016-11-30T00:00:00Z","relpermalink":"/pt/project/2016/nextel-digital-release/","section":"project","summary":"Introdu√ß√£o Sum√°rio A Nextel planejou desenvolver uma aplica√ß√£o m√≥vel para reduzir seus custos operacionais com call centers e reduzir o contact rate.","tags":["devops"],"title":"Nextel Digital Release","type":"project"},{"authors":null,"categories":null,"content":"Introdu√ß√£o Sum√°rio Para poder inovar e se manter em um mercado em constante mudan√ßa e evolu√ß√£o, Dotz passou por um processo de transforma√ß√£o digital e teve a ajuda de alguns consultores neste percurso.\nEntre as iniciativas para se aproximar de um modelo digital, surgiu a implementa√ß√£o de um Data Lake, com o requisito de ser serverless e cloud-native, auxiliando no processo de tomada de decis√£o e encurtando o time-to-market durante o lan√ßamento de novos produtos.\nProblem√°tica A Dotz √© uma das maiores empresas no campo de programas de fidelidade no Brasil, e enfrentaria um grande n√∫mero de problemas com desconex√£o de dados dificultando a an√°lise do comportamento de seus usu√°rios. Como eles receberam dados de in√∫meros supermercados e lojas, √© dif√≠cil agrupar os produtos, j√° que o nome √© diferente dependendo da fonte. Para ajudar nesta an√°lise, eles decidiram construir um Data Lake.\nSolu√ß√£o Implementa√ß√£o T√©cnica Constru√≠mos e implantamos uma arquitetura gerenciada da Big Data usando a Plataforma Cloud do Google (GCP) para suportar esta estrat√©gia e permitir uma vis√£o de 360 graus dos clientes (usu√°rios com pontos a.k.a. Dotz) e parceiros que oferecem o programa de fidelidade.\nO design foi focado em servi√ßos ger√™nciados pela nuvem e serverless oferecida pelo Google, servindo as principais compet√™ncias de um Data Lake como o armazenamento escal√°vel usando o Google Cloud Storage, e o Google BigQuery. Com parte do processo rodando containerizado em Kubernetes, respons√°vel pela limpeza de dados e gerenciar o ETL.\nTransmitimos dados com o Apache Beam rodando sob o Google DataFlow, processamento em massa paralelo com Apache Spark jobs executados no Google DataProc, an√°lise explorat√≥ria com o Google DataLab, Machine Learning Analysis com o Google ML e visualiza√ß√£o de dados no Google Data Studio.\nOs dados s√£o transportados por meio de um modelo data-driven, onde os dados foram planejados para streaming, including o ETL (que funciona em um micro-batch, para permitir a explora√ß√£o em near-real-time). Estes dados passam pelo pipeline de dados utilizando o servi√ßo de mensageria do Google Pub/Sub, em que cada mensagem √© serializada utilizando o formato Avro, reduzindo a carga e permitindo que o transporte seja econ√¥mico, r√°pido e confi√°vel.\nImpacto e resultados Tudo isso permitiu √† Dotz ter uma melhor estrutura em sua plataforma anal√≠tica, previamente gerenciada em uma grande inst√¢ncia do MS SQL Server, sendo deslocada para um Data Lake com camadas que permitem a categoriza√ß√£o, governan√ßa, qualidade e seguran√ßa dos dados.\nSuporte a processos anal√≠ticos de dados dos usu√°rios, explora√ß√£o √°gil e monetiza√ß√£o de seus conhecimentos sobre o comportamento dos clientes.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1589823897,"objectID":"425ab80046da88c0b83001b57e4e7a84","permalink":"https://macunha.me/pt/project/2017/dotz-data-labs/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/pt/project/2017/dotz-data-labs/","section":"project","summary":"Introdu√ß√£o Sum√°rio Para poder inovar e se manter em um mercado em constante mudan√ßa e evolu√ß√£o, Dotz passou por um processo de transforma√ß√£o digital e teve a ajuda de alguns consultores neste percurso.","tags":["data-eng"],"title":"Dotz Data Labs","type":"project"}]