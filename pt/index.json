[{"authors":["admin"],"categories":null,"content":"Ol√°!\nEu sou Matheus Cunha (ou s√≥ Macunha), um Engenheiro de Sistemas focado em DevOps e Engenharia de Dados.\nTenho experi√™ncia em arquitetura de sistemas descentralizados e altamente dispon√≠veis, lan√ßei projetos nas principais n√∫vens: AWS, Azure e GCP, assim como ambientes multi-cloud e n√∫vem h√≠brida com servidores on-premises.\nAtuei como consultor em diversas empresas, ajudando-as a ser mais future-proof e competitivas em um ambiente altamente mut√°vel. Sempre procuro maneiras de melhorar, aprender mais e ir mais longe. Buscando atingir um alto potencial para as empresas e os projetos em que me envolvo.\nQuanto ao lado techy nerd, sou apaixonado por tecnologia open-source altamente capacitado em Linux, que escreve c√≥digos em Java, Python, Go, JavaScript (Node.js) e Lua.\nGeralmente, utilizando os seguintes databases:\n PostgreSQL e MySQL (para dados relacionais); InfluxDB (incluindo a stack TICK) para time-series; Elasticsearch (incluindo ELK e EBK) para logging e busca; Hadoop (com HDFS, S3 ou Google Cloud Storage) para data warehousing; Kafka como message broker de alto throughput; and Redis para caching e message broker de m√©dio throughput.  Monitorando a infrastrutura com Prometheus sendo apoiado pela InfluxData TICK stack. Ansible para ter ger√™ncia de configura√ß√£o como c√≥digo junto com Terraform (de prefer√™ncia implementando infra imut√°vel), e rodando containers em produ√ß√£o orquestrados pelo Kubernetes.\nüòÑ\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"pt","lastmod":1628755196,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://macunha.me/pt/author/matheus-cunha/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/pt/author/matheus-cunha/","section":"authors","summary":"Ol√°!\nEu sou Matheus Cunha (ou s√≥ Macunha), um Engenheiro de Sistemas focado em DevOps e Engenharia de Dados.\nTenho experi√™ncia em arquitetura de sistemas descentralizados e altamente dispon√≠veis, lan√ßei projetos nas principais n√∫vens: AWS, Azure e GCP, assim como ambientes multi-cloud e n√∫vem h√≠brida com servidores on-premises.","tags":null,"title":"Matheus Cunha","type":"authors"},{"authors":null,"categories":["Tutorials"],"content":"Introduction Apache Spark Operator para Kubernetes Desde o seu lan√ßamento em 2014 pela Google, o Kubernetes tem ganhado muita popularidade junto com o pr√≥prio Docker e desde 2016 passou a ser o de facto Container orchestrator, estabelecido como um padr√£o de mercado. Possuindo vers√µes gerenciadas em todas as major Clouds[1] [2] [3] (inclusive Digital Ocean e Alibaba).\nToda essa popularidade tem atra√≠do novas implementa√ß√µes e use-cases para o orquestrador, dentre eles a execu√ß√£o de Stateful applications incluindo bancos de dados em containers.\nQual seria a necessidade de ter um banco de dados orquestrado? √ìtima pergunta. Por hoje, vamos focar na utiliza√ß√£o do Spark Operator para executar Spark jobs em Kubernetes.\nA id√©ia do Spark Operator surgiu em 2016, antes disso haviam apenas alguns jeitinhos, por exemplo: com Apache Zeppelin dentro do Kubernetes, ou ent√£o, mais refinado ainda criando o seu pr√≥prio Apache Spark cluster dentro do Kubernetes (exemplo do reposit√≥rio oficial do Kubernetes) que usaria o Spark Standalone mode.\nPor√©m, executar nativamente seria muito mais interessante pois poderia aproveitar o Kubernetes Scheduler para a√ß√µes relacionadas √† aloca√ß√£o dos recursos no cluster, dando mais elasticidade e uma interface mais simples para gerenciar os workloads no Apache Spark.\nConsidernando esses pontos o desenvolvimento do Apache Spark Operator ganhou aten√ß√£o, foi mergeado e publicado na vers√£o do Apache Spark 2.3.0 em Fevereiro de 2018.\nSe voc√™ estiver interessado em ler mais sobre a proposta do Apache Spark Operator, existe um design document publicado no Google Docs.\nPor que Kubernetes? Como atualmente as empresas est√£o buscando se reinventar por meio da t√£o falada transforma√ß√£o digital para que possam ter competitividade e, principalmente, sobreviver diante de um mercado cada vez mais din√¢mico, √© comum ver abordagens que incluam Big Data, Intelig√™ncia Artificial e Cloud Computing [1] [2] [3].\nPara compreender os benef√≠cios de utilizar Cloud ao inv√©s de On-premises no contexto de Big Data vale a pena ler o artigo da Databricks, que √© a empresa fundada pelos criadores do Apache Spark.\nComo n√≥s vemos uma ado√ß√£o de Cloud Computing generalizada (at√© por empresas que teriam condi√ß√µes de bancar o pr√≥prio hardware), tamb√©m podemos notar que na maiorira dessas implementa√ß√µes de Cloud n√£o existem clusters de Apache Hadoop j√° que os times de Dados (BI/Data Science/Analytics) optam cada vez mais por utilizar ferramentas como Google BigQuery ou AWS Redshift. Portanto, n√£o faz sentido subir um Hadoop apenas para utilizar o YARN como gerenciador os recursos.\nUma alternativa √© a utiliza√ß√£o de provisionadores de clusters Hadoop como o Google DataProc ou o AWS EMR para a cria√ß√£o de clusters ef√™meros. Apenas para nomear algumas op√ß√µes.\nPara entender melhor o design do Spark Operator, recomendo a leitura da documenta√ß√£o gerada pela equipe da GCP no GitHub.\nHora de meter a m√£o na massa! Aquecendo o motor Agora que toda a palavra j√° foi passada, vamos ao hands-on para mostrar a coisa acontecendo. Para isso, vamos usar:\n Docker como motor de container no Kubernetes, e constru√ß√£o da imagem (link para instala√ß√£o); Minikube (link para instala√ß√£o) para facilitar o provisionamento do Kubernetes (sim, ser√° uma execu√ß√£o local); Para interagir com a API do Kubernetes √© preciso ter o kubectl instalado. Se voc√™ n√£o tiver, siga as instru√ß√µes aqui. uma vers√£o compilada do Apache Spark que seja maior do que a 2.3.0.  voc√™ pode tanto compilar do c√≥digo fonte, que vai tomar algumas horas at√© terminar, quanto fazer o download de uma vers√£o compilada aqui (recomendado).    Assim que o Apache estiver descompactado, vamos adicionar o caminho no PATH para facilitar a execu√ß√£o:\nexport PATH=${PATH}:/path/to/apache-spark-X.Y.Z/bin  Criando o \u0026ldquo;cluster\u0026rdquo; com Minikube Agora, para ter um Kubernetes vamos iniciar um minikube com o prop√≥sito de rodar um dos exemplos dispon√≠veis no reposit√≥rio do Spark chamado SparkPi apenas para demonstra√ß√£o.\nminikube start --cpus=2 \\ --memory=4g  Buildando a imagem Docker Vamos utilizar o Docker daemon do Minikube para n√£o depender de um registry externo (e s√≥ gerar lixo na VM, facilitando a limpeza depois). Para isso, o minikube tem um wrapper que facilita a nossa vida:\neval $(minikube docker-env)  Ap√≥s ter configurado as vari√°veis de ambiente para o Docker daemon, vamos precisar de uma imagem Docker para executar os jobs. Existe um shell script no reposit√≥rio do Spark para ajudar com isso. Considerando que o PATH est√° configurado corretamente, basta executar:\ndocker-image-tool.sh -m -t latest build  Obs.: O par√¢metro -m aqui indica que √© um build para o minikube.\nVamos pegar a via expressa para executar o SparkPi, usando o mesmo comando que seria utilizado para um cluster Spark spark-submit.\nPor√©m, o Spark Operator d√° suporte a defini√ß√£o de jobs no \u0026ldquo;dialeto do Kubernetes\u0026rdquo; usando CRD, aqui tem alguns exemplos - para depois.\nFire in the hole! Cuidado com o v√£o entre a vers√£o do Scala e a plataforma quando estiver parametrizando o job:\nspark-submit --master k8s://https://$(minikube ip):8443 \\ --deploy-mode cluster \\ --name spark-pi \\ --class org.apache.spark.examples.SparkPi \\ --conf spark.executor.instances=2 \\ --executor-memory 1024m \\ --conf spark.kubernetes.container.image=spark:latest \\ local:///opt/spark/examples/jars/spark-examples_2.11-X.Y.Z.jar # aqui  O que temos de novidade √©:\n --master: Aceita o prefixo k8s:// na URL, para o endpoint da API do Kubernetes, exposta pelo commando https://$(minikube ip):8443. Ali√°s, se estiver interessado, isso √© um command substitution no shell; --conf spark.kubernetes.container.image=: Configura√ß√£o para a imagem Docker que ser√° executada no Kubernetes.  Com o output:\n... 19/08/22 11:59:09 INFO LoggingPodStatusWatcherImpl: State changed, new state: pod name: spark-pi-1566485909677-driver namespace: default labels: spark-app-selector -\u0026gt; spark-20477e803e7648a59e9bcd37394f7f60, spark-role -\u0026gt; driver pod uid: c789c4d2-27c4-45ce-ba10-539940cccb8d creation time: 2019-08-22T14:58:30Z service account name: default volumes: spark-local-dir-1, spark-conf-volume, default-token-tj7jn node name: minikube start time: 2019-08-22T14:58:30Z container images: spark:docker phase: Succeeded status: [ContainerStatus(containerID=docker://e044d944d2ebee2855cd2b993c62025d 6406258ef247648a5902bf6ac09801cc, image=spark:docker, imageID=docker://sha256:86649110778a10aa5d6997d1e3d556b35454e9657978f3 a87de32c21787ff82f, lastState=ContainerState(running=null, terminated=null, waiting=null, additionalProperties={}), name=spark-kubernetes-driver, ready=false, restartCount=0, state=ContainerState(running=null, terminated=ContainerStateTerminated(containerID=docker://e044d944d2ebe e2855cd2b993c62025d6406258ef247648a5902bf6ac09801cc, exitCode=0, finishedAt=2019-08-22T14:59:08Z, message=null, reason=Completed, signal=null, startedAt=2019-08-22T14:58:32Z, additionalProperties={}), waiting=null, additionalProperties={}), additionalProperties={})] 19/08/22 11:59:09 INFO LoggingPodStatusWatcherImpl: Container final statuses: Container name: spark-kubernetes-driver Container image: spark:docker Container state: Terminated Exit code: 0  Para ver o resultado do job (e toda a execu√ß√£o), podemos mandar um kubectl logs passando o nome do pod do driver como par√¢metro:\nkubectl logs $(kubectl get pods | grep 'spark-pi.*-driver')  Que traz o output (algumas entradas foram omitidas), parecido com:\n... 19/08/22 14:59:08 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 52 ms on 172.17.0.7 (executor 1) (2/2) 19/08/22 14:59:08 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool19/08/22 14:59:08 INFO DAGScheduler: ResultStage 0 (reduce at SparkPi.scala:38) finished in 0.957 s 19/08/22 14:59:08 INFO DAGScheduler: Job 0 finished: reduce at SparkPi.scala:38, took 1.040608 s Pi is roughly 3.138915694578473 19/08/22 14:59:08 INFO SparkUI: Stopped Spark web UI at http://spark-pi-1566485909677-driver-svc.default.svc:4040 19/08/22 14:59:08 INFO KubernetesClusterSchedulerBackend: Shutting down all executors 19/08/22 14:59:08 INFO KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint: Asking each executor to shut down 19/08/22 14:59:08 WARN ExecutorPodsWatchSnapshotSource: Kubernetes client has been closed (this is expected if the application is shutting down.) 19/08/22 14:59:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped! 19/08/22 14:59:08 INFO MemoryStore: MemoryStore cleared 19/08/22 14:59:08 INFO BlockManager: BlockManager stopped 19/08/22 14:59:08 INFO BlockManagerMaster: BlockManagerMaster stopped 19/08/22 14:59:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped! 19/08/22 14:59:08 INFO SparkContext: Successfully stopped SparkContext 19/08/22 14:59:08 INFO ShutdownHookManager: Shutdown hook called 19/08/22 14:59:08 INFO ShutdownHookManager: Deleting directory /tmp/spark-aeadc6ba-36aa-4b7e-8c74-53aa48c3c9b2 19/08/22 14:59:08 INFO ShutdownHookManager: Deleting directory /var/data/spark-084e8326-c8ce-4042-a2ed-75c1eb80414a/spark-ef8117bf-90 d0-4a0d-9cab-f36a7bb18910  O resultado aparece no stdout:\n19/08/22 14:59:08 INFO DAGScheduler: Job 0 finished: reduce at SparkPi.scala:38, took 1.040608 s Pi is roughly 3.138915694578473  Para finalizar, vamos deletar a VM que o Minikube gera, para limpar o ambiente (a menos que voc√™ queira continuar brincando com ele):\nminikube delete  √öltimas palavras Espero ter dispertado bastante curiosidade e algumas ideias para ir al√©m no desenvolvimento dos seus workloads de Big Data. Se tiver alguma d√∫vida ou sugest√£o, n√£o deixe de postar na se√ß√£o de coment√°rios.\n","date":1590094857,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1592457555,"objectID":"359ac010e6e64574925f2121741a0cf4","permalink":"https://macunha.me/pt/post/2020/05/quickstart-apache-spark-no-kubernetes/","publishdate":"2020-05-21T23:00:57+02:00","relpermalink":"/pt/post/2020/05/quickstart-apache-spark-no-kubernetes/","section":"post","summary":"Utilizando Apache Spark Operator no Kubernetes para agilizar seus workflows de Big Data com abordagem cloud-native sem depender de um Hadoop cluster.","tags":["data-engineering","kubernetes"],"title":"Quickstart: Apache Spark no Kubernetes","type":"post"},{"authors":null,"categories":null,"content":"Introdu√ß√£o Resumo ReclameAQUI √© um neg√≥cio interessante e √∫nico. √â um agregador de conte√∫do para troca de experi√™ncias dos clientes (especialmente m√°s experi√™ncias) sobre compras (online e offline). No entanto, vai al√©m de um simples \u0026ldquo;site de reclama√ß√µes\u0026rdquo;, oferecendo uma interface para as empresas responderem √†s reclama√ß√µes, ajudando os clientes com seus problemas.\nO servi√ßo √© simplesmente o maior neste sentido (mundial) recebendo diariamente 600K visitantes √∫nicos, buscando a reputa√ß√£o de uma empresa antes de fechar um neg√≥cio/compra.\nProblema Apesar de j√° estarem avan√ßados na abordagem de business digital, tendo a maioria dos servi√ßos hospedados em Cloud computing e cultura anal√≠tica, seu Data Lake precisava de alguns upgrades. O maior motivador deste projeto foram as contas alt√≠ssimas da GCP, especialmente relacionadas ao consumo de dados no BigQuery.\nAl√©m das tarefas de redu√ß√£o de custos e otimiza√ß√£o do processo de ingest√£o de dados, aproveitamos a oportunidade para implementar criptografia de dados at-rest, governan√ßa e obfusca√ß√£o durante as queries contra o data lake. Tornando os dados acess√≠veis por todos na empresa, controlando o acesso e gerenciamento de identidade atrav√©s do LDAP (auditando cada acesso, para estar em total conformidade com a GDPR), pudemos oferecer um Data Lake self-service para que diferentes atores empresariais pudessem satisfazer suas necessidades \u0026ldquo;bebendo\u0026rdquo; do lake.\nSolu√ß√£o Implementa√ß√£o t√©cnica Os principais objetivos foram otimiza√ß√£o de custos do Data Lake existente, melhoria (e extens√£o) dos pipelines de ingest√£o de dados existentes, e aperfei√ßoamentos na seguran√ßa.\nPartindo pela otimiza√ß√£o de custos do Data Lake, reimplantamos os pipelines de ingest√£o de dados, utilizando uma √°rea de \u0026ldquo;landing\u0026rdquo; para dados brutos e posteriormente transforma√ß√µes eram realizadas para adequar os modelos de dados desejados. Salvando os resultados em outras camadas do Data Lake, para atingir maior performance nas queries.\nRemovemos as Streaming inserts no BigQuery adicionando um step para fazer load dos dados ao fim da ingest√£o. O Apache NiFi foi o principal software respons√°vel pela orquestra√ß√£o e execu√ß√£o da ingest√£o de dados, abrangendo tamb√©m as melhorias da ingest√£o de dados atrav√©s da reengenharia dos processos.\nA auditoria no Data Lake foi gerenciada atrav√©s do Apache Ranger. Para ter suporte total, implementamos um driver JDBC usando um componente do Apache Calcite chamado Avatica. A autentica√ß√£o para o Apache Ranger passou por um plugin personalizado (tamb√©m desenvolvido durante o projeto) para LDAP consumindo informa√ß√µes de usu√°rios do Google Cloud Identity, refletindo a organiza√ß√£o de grupos e usu√°rios existente do Google Suite.\nPara tornar o jogo mais interessante, containerizamos o workflow e utilizamos bastante Kubernetes (GKE) para gerenciar estes componentes. A maioria dos componentes Apache n√£o tinha Helm Charts na √©poca e n√≥s os desenvolvemos e tornamos alguns open-source.\nImpacto e resultados Durante o tempo do projeto pudemos medir uma estimativa de aproximadamente 56% de redu√ß√£o de custos do Data Lake atrav√©s da otimiza√ß√£o de recursos e reengenharia de processos, especialmente a remo√ß√£o de Streaming inserts no BigQuery.\nObtivemos progresso relevante em termos de seguran√ßa e governan√ßa durante o projeto, com a introdu√ß√£o do Apache Ranger e auditoria de acesso e uso do Data Lake, fornecendo capacidades avan√ßadas de seguran√ßa √† ReclameAQUI, que se antecipou frente √† LGPD e as preocupa√ß√µes em quest√£o da privacidade dos dados.\n","date":1563667200,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1614436244,"objectID":"a3e6c3c9035888d3f6ad0c80e11dd615","permalink":"https://macunha.me/pt/project/reclameaqui-data-lake/","publishdate":"2019-07-21T00:00:00Z","relpermalink":"/pt/project/reclameaqui-data-lake/","section":"project","summary":"Data Lake containerizado rodando em GCP, utilizando Kubernetes (GKE) para orquestrar componentes do ecossistema Apache, com GCS para armazenamento de dados e BigQuery como interface anal√≠tica.\nGovernan√ßa e seguran√ßa totalmente implementadas utilizando os usu√°rios e grupos do Google Suite por meio de LDAP, dando aos stakeholders total autonomia para consumir dados (com auditoria).","tags":["cloud","data-engineering","kubernetes"],"title":"ReclameAQUI Data Lake","type":"project"},{"authors":null,"categories":["DevOps","Agile Manifesto"],"content":"Introdu√ß√£o Principais benef√≠cios que uma companhia geralmente espera e encontra na ado√ß√£o da cultura:\nReleases mais r√°pidos e baratos Como os releases ser√£o frequentes, as entregas acabam sendo pequenas. Entregas pequenas trazem o benef√≠cio de aumentar a velocidade no ciclo de desenvolvimento (entregando sempre)\nSuporte operacional melhorado com ajustes r√°pidos Caso haja alguma falha durante a entrega, o impacto √© menor pois a quantidade de modifica√ß√µes √© pequena, assim como o rollback √© r√°pido.\nMelhor time to market (TTM) O software ser√° entregue muito mais cedo, quando ainda for um MVP. Os clientes ser√£o integrados como parte do processo de desenvolvimento, trazendo insights e feedbacks para o time. Permitindo assim que haja uma velocidade maior de lan√ßamento no mercado.\nProdutos de qualidade superior Como foi falado antes, falhar cedo impede que defeitos sejam entregues em produ√ß√£o\nAssim como:\n Menor volume de defeitos no produto como um todo; Aumento na frequ√™ncia de novas features e releases; Processos de desenvolvimento apropriados nos times, incluindo automa√ß√£o.  Agora que entendemos o POR QUE, vamos ao COMO Continuous releases (integration, delivery, deployment) Geralmente segue uma abordagem de versionamento de c√≥digo (por meio do Git) utilizando branches espec√≠ficas para cada ambiente.\nContinuous integration Execu√ß√£o autom√°tica dos testes unit√°rios, integrados e tamb√©m de qualidade de c√≥digo na branch, para garantir que n√£o houve quebra de funcionamento do peda√ßo modificado do c√≥digo.\nContinuous delivery Empacotamento do software que est√° testado e aprovado, para deixar ele em algum lugar que seja poss√≠vel fazer um deploy posteriormente. Exemplos s√£o libs entregues em reposit√≥rios para ser integradas no c√≥digo durante o pr√≥ximo update e deploy de c√≥digo\nContinuous deployment Ap√≥s conseguir completar todos os passos anteriores, √© poss√≠vel fazer deploy automatizado direto nos ambientes, quando o time estiver com mais confian√ßa em rela√ß√£o √†s ferramentas que testam, assim como com a quest√£o de assumir riscos e entender que existe a possibilidade de falhar em ambientes de teste, sem preocupa√ß√µes.\nConfiguration (e/ou Infrastructure) as code Para que seja poss√≠vel testar o software com assertividade, e entender que ele ir√° transitar entre os ambientes sem mudar de comportamento, √© de extrema import√¢ncia que as configura√ß√µes sejam tamb√©m c√≥digo. Isso permite que as configura√ß√µes sejam tamb√©m versionadas, acompanhando o c√≥digo. Garantindo tamb√©m uma uniformidade entre os ambientes, que possibilita:\n Redu√ß√£o nos custos de manuten√ß√£o, tendo um ponto √∫nico para olhar e entender o funcionamento do sistema; Facilidade para recriar a infraestrutura, caso seja necess√°rio mover tudo para outro lugar, isso pode acontecer com poucas intera√ß√µes manuais; Permite que haja code review da infraestrutura e das configura√ß√µes, que por consequ√™ncia traz uma cultura de colabora√ß√£o no desenvolvimento, compartilhamento do conhecimento e aumenta a democratiza√ß√£o da infra; Documenta√ß√£o como c√≥digo, ajudando novos membros do time a terem um warm up mais r√°pido.  Esses pontos foram bem estressados pelo time da Heroku, e deram origem ao famoso paper: The Twelve-Factor App. Uma leitura muito boa para a explica√ß√£o dos benef√≠cios sobre ger√™ncia de configura√ß√£o.\nMonitoramento e self-healing Ao fim de todo o processo de entrega, o software dever√° estar sendo monitorado, para que n√£o seja necess√°rio esperar um report externo de falhas, garantindo que as a√ß√µes sejam pr√≥-ativas e n√£o reativas.\nGarantir que o monitoramento esteja maduro, tamb√©m nos permite automatizar a parte de rea√ß√£o aos alertas, criando um sistema de self-healing em que a√ß√µes (scripts) s√£o executados para corrigir poss√≠veis falhas conhecidas na infraestrutura. Permitindo assim que todos possam dormir tranquilamente de noite, sem ter que ficar preocupado com o plant√£o tocar e ter que ler documenta√ß√£o de madrugada. (Se voc√™ j√° teve experi√™ncia com isso, sabe com certeza o quanto √© ruim).\nEscalando assim apenas os casos que forem extremas exce√ß√µes (erros n√£o conhecidos/esperados) no processo para o plantonista atuar, garantindo uma maior sa√∫de na opera√ß√£o.\nAutoma√ß√£o de processos Todo o processo que estiver causando Muda √© alvo de automa√ß√£o, para que as pessoas possam trabalhar com mais agilidade. Bons exemplos de processos que costumam ser automatizados s√£o:\n Deployment; Self-healing (resili√™ncia do sistema em resposta √†s anomalias); Renova√ß√£o de Certificados; Execu√ß√£o de testes (unit√°rios, de integra√ß√£o, funcionais, etc); Monitoramento (com auto-discovery); Governan√ßa de usu√°rios;  DevOps toolchain Uma combina√ß√£o de ferramentas para facilitar a manuten√ß√£o e opera√ß√£o do sistema, seguindo o seguinte fluxo:\n    Obs.: Qualquer semelhan√ßa com o PDCA √© mera certeza.\n  Plan: Fase de planejamento do projeto, em que s√£o coletados os feedbacks para levantamento de requisitos, e cria√ß√£o do backlog; Create: Cria√ß√£o de um entreg√°vel (para validar uma hip√≥tese), como um MVP; Verify: Passar o entreg√°vel para a fase de testes; Package: Empacotar o entreg√°vel (build) para conseguir colocar ele em algum ambiente de testes; Release: Fazer o deployment do entreg√°vel empacotado; Configure: Realizar a configura√ß√£o do entreg√°vel no ambiente de testes, tentando chegar o mais pr√≥ximo poss√≠vel do twelve-factor app. Monitor: Ap√≥s fazer o deployment no ambiente, acompanhar as m√©tricas de neg√≥cio e infraestrutura, para garantir que est√° tudo funcionando conforme o esperado.  Conclus√£o Durante a implementa√ß√£o dessas t√©cnicas √© poss√≠vel observar melhoras no processo de desenvolvimento, os ganhos mais not√°veis s√£o:\n Melhoria no engajamento do time; Compartilhamento de conhecimento; Redu√ß√£o de bottlenecks; Mais tempo livre para realizar trabalho que realmente importa (agrega valor para a experi√™ncia do usu√°rio ou gera impacto); Maior confian√ßa ao entregar software.  ","date":1547244e3,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1592457555,"objectID":"234c851ba757bb2bbbda260c3e11abe3","permalink":"https://macunha.me/pt/post/2019/01/devops-benefits/","publishdate":"2019-01-11T22:00:00Z","relpermalink":"/pt/post/2019/01/devops-benefits/","section":"post","summary":"Benef√≠cios da implementa√ß√£o da cultura DevOps nos neg√≥cios, porque esta √© uma op√ß√£o vi√°vel e a _big picture_ resumida do mundo DevOps de um ponto de vista neg√≥cios.","tags":["devops","culture","agile","lean"],"title":"DevOps: Os benef√≠cios da implementa√ß√£o","type":"post"},{"authors":null,"categories":["DevOps","Agile Manifesto"],"content":"Introdu√ß√£o First of all, it‚Äôs all about Agile.\nA metodologia DevOps foi criada utilizando os conceitos dos m√©todos √Ågeis, para entregar um grande valor durante o processo de desenvolvimento de software, automatizando o release de features com pipelines, para conseguir provar hip√≥teses mais r√°pido e assim se adaptar mais r√°pido √†s mudan√ßas por meio de uma abordagem ‚Äúfail-fast‚Äù. Essas mudan√ßas s√£o mais culturais do que t√©cnicas, portanto √© comum dizer que DevOps √© cultura.\nA implementa√ß√£o de DevOps acontece por meio da automa√ß√£o de processos, tendo muito forte dentro dessa implementa√ß√£o a reengenharia de processos da empresa. A implementa√ß√£o da parte t√©cnica √© simples e f√°cil se comparada com a mudan√ßa de comportamento das pessoas. Portanto, √© bastante confuso o papel que um ‚ÄúEngenheiro/Analista DevOps‚Äù desempenharia, no meio dessa confus√£o, existem muitos SysAdmins e Analistas de Infra assumindo o papel de ‚ÄúDevOps‚Äù.\nFirst things first, Lean √© a base do Agile A realidade n√£o √© t√£o feliz quanto parece. Depois da segunda guerra mundial, o Jap√£o estava destru√≠do e com poucos recursos, ap√≥s ter perdido a guerra. Com uma quantia limitada de recursos, o pa√≠s precisou se reinventar e sobreviver ap√≥s uma √©poca de forte depress√£o, durante essa √©poca dois caras ficaram famosos pelo trabalho realizado dentro de uma empresa, que mais tarde teve o nome dedicado ao modelo que foi criado.\nEsses caras eram Eiji Toyoda e Taiichi Ohno, que trabalhavam para a Toyota Motor Corporation. Foram os fundadores do modelo de produ√ß√£o Toyota, tamb√©m conhecido como Toyotismo.\nToyota deu origem ao Lean Lean √© uma metodologia que ensina a otimizar os processos da empresa; end-to-end, para dar mais aten√ß√£o √†s tarefas que entregam valor ao consumidor final, incentivando ao m√°ximo a remo√ß√£o de bottlenecks no processo, assim como a an√°lise de tarefas que s√£o desperd√≠cio (definidas pelos 3M) para que sejam identificadas e removidas.\nEssas tarefas consideradas desperd√≠cio s√£o classificadas como 3M dentro do Lean que representam: Muda, Mura, e Muri. Outro ponto importante a destacar no processo √© a utiliza√ß√£o do m√©todo nomeado Kaizen (continuous improvement), com foco em melhorar continuamente buscando atingir um n√≠vel de excel√™ncia em qualidade.\nA qualidade faz parte da cultura japonesa, pois existe a cren√ßa de que um produto de qualidade traz o cliente de volta, mesmo que os produtos demorem mais para estragar, os clientes ser√£o fi√©is a eles, pois ter√£o uma boa experi√™ncia. Antes mesmo de falarmos sobre user experience, eles j√° estavam pensando nisso.\nKaizen Um mindset que ajuda a olhar para cada parte do processo exclusivamente e pensar nas melhorias, envolvendo as pessoas que fazem parte do processo, assim incentiva que haja a inclus√£o dessas pessoas nas decis√µes de mudan√ßa, j√° que:\n Fica muito mais f√°cil de aceitar uma mudan√ßa quando ela n√£o √© imposta (top-down); H√° uma absor√ß√£o maior das mudan√ßas pelas pessoas, quando elas s√£o inclu√≠das no processo; As pessoas que s√£o inclu√≠das no processo trazem as suas preocupa√ß√µes e sugest√µes, que contribuem positivamente com a evolu√ß√£o da mudan√ßa, tornando as ideias propostas mais robustas devido ao incentivo em rela√ß√£o √† contribui√ß√£o.  O processo de defini√ß√£o das melhorias por meio de Kaizen acontece (normalmente) na seguinte ordem:\n    Definir objetivos com base em dados; Revisar o estado atual e desenvolver um plano de melhoria; Implementar a melhoria; Revisar a implementa√ß√£o e corrigir o que n√£o funciona; Reportar os resultados e determinar os itens a serem monitorados.  Esse processo √© bastante chamado de PDCA: Plain-Do-Control-Act, que se resume em:\n Plan (desenvolver a hip√≥tese); Do (executar um experimento); Check (validar os resultados); Act (refinar o experimento e recome√ßar).  3M: Muda, Mura, Muri Muda (desperd√≠cio) Qualquer atividade que consuma tempo sem agregar valor ao consumidor final. Como por exemplo:\n produ√ß√£o em excesso; tempo parado (ocioso) no processo; defeito nos produtos.  √â importante lembrar que existem n√≠veis diferentes de Muda que podem ser ou n√£o removidos com rapidez, e a classifica√ß√£o depende do tempo para remo√ß√£o.\nUm exemplo de Muda mais demorado √© a descontinua√ß√£o de um software legado que acaba tendo ciclos mais longos de release, causando tempo ocioso nos times, muitas vezes uma rotina de testes longa e manual.\nMura (desigualdade) Atividades que s√£o muito vari√°veis e imprevis√≠veis, gerando resultados diferentes em todas as execu√ß√µes. Por exemplo: a execu√ß√£o de tarefas que n√£o foram bem planejadas e acabam chegando com prazos r√≠gidos. S√£o executadas na correria, gerando um desgaste, desespero, e ainda por cima, ao terminar deixam as pessoas que executaram essas tarefas esperando (seja um feedback, ou ent√£o a confirma√ß√£o de que est√° finalizado).\nMuri (sobrecarga) Exigir que as pessoas (ou os equipamentos) trabalhem al√©m do limite, para atingir algum tipo de meta ou expectativa, gerando cansa√ßo e consequentemente falhas durante o processo. Essas falhas s√£o geralmente erros humanos causados pelo cansa√ßo durante o trabalho excessivo.\nVoltando ao Agile‚Ä¶ No ano 2000 um grupo de 17 pessoas se encontrou em um resort em Oregon para conversar sobre ideias que poderiam melhorar o fluxo de desenvolvimento de software. Depois de um ano de amadurecimento das ideias, essas pessoas se encontraram de novo e publicaram as ideias, que hoje conhecemos como: Agile Manifesto.\nOs principais pontos s√£o:\n Individuals and interactions over processes and tools Working software over comprehensive documentation Customer collaboration over contract negotiation Responding to change over following a plan  Vou me restringuir a explica√ß√£o desses pontos com o ponto de vista DevOps, para n√£o fugir (mais) do tema.\nIndividuals and interactions over processes and tools\nAs pessoas devem receber o kit de ferramentas (tooling) apropriado para trabalhar e ent√£o serem empoderados para realizar seu trabalho. As intera√ß√µes entre pessoas √© extremamente incentivada, para o compartilhamento de conhecimento e tamb√©m para facilitar o fluxo criativo dentro dos times de desenvolvimento.\nUm excelente exemplo de intera√ß√£o incentivada por meio de DevOps √© o h√°bito de code review. Considerando que pequenas partes do software ser√£o iteradas e aprovadas no pipeline passando por diferentes ambientes, de maneira autom√°tica, o melhor jeito de prevenir defeitos √© por meio de code review.\nEsse h√°bito traz benef√≠cio como:\n Compartilhamento de conhecimento no time; Observa√ß√£o do problema em diferentes pontos de vista; Engajamento no time; Redu√ß√£o no n√∫mero de bugs.  Working software over comprehensive documentation\nAqui existe um trick na quest√£o do working software, um software que funciona n√£o √© ‚Äúcompilou, t√° funcionando‚Äù. O software que funciona √© o que atende aos requisitos do usu√°rio; i.e. o software que resolve o problema e as dores do usu√°rio.\nComo o mercado √© muito din√¢mico, e evolui com grande velocidade, muitas vezes durante o projeto de desenvolvimento de software os requisitos mudam devido a fatores externos. Portanto, sabendo que n√£o √© poss√≠vel prever todos os fatores, muitas gambiarras s√£o feitas no meio do caminho e documentadas, para que o usu√°rio final aprenda a lidar com as falhas, e executar os workarounds, gastando mais esfor√ßo do que seria necess√°rio para realizar as tarefas por meio do software.\n Entregar frequentemente software funcionando, de poucas semanas a poucos meses, com prefer√™ncia √† menor escala de tempo\n Incentivando assim que hajam deployments tanto quanto o poss√≠vel, para que as falhas aconte√ßam o mais cedo poss√≠vel, permitindo assim que o impacto delas seja bem menor.\nFail-fast! As falhas s√£o compreendidas e incentivadas, pois faz parte do mindset entender que:\n S√≥ erra quem faz; Falhar √© o melhor jeito de aprender e evoluir; Shit happens.  Nada como citar a Lei de Murphy para melhor contextualizar\n \u0026ldquo;Se algo pode dar errado, dar√°.\u0026rdquo;\n Portanto √© melhor que as falhas ocorram cedo, enquanto o custo de corre√ß√£o ainda √© baixo. Falhar em um ambiente controlado de testes, permite que a corre√ß√£o seja muito mais r√°pida (e barata) do que seria caso a corre√ß√£o acontecesse j√° em produ√ß√£o.\nPara que essa abordagem tenha sucesso, existe a premissa de que os ambientes sejam c√≥pias de produ√ß√£o, ou pelo menos que seja o mais pr√≥ximo poss√≠vel. Do contr√°rio, haver√£o mudan√ßas de comportamento no software entre os ambientes, inviabilizando o ambiente de testes.\nCaso os ambientes sejam divergentes, a promo√ß√£o de bugs para produ√ß√£o ser√° muito frequente, causando falhas tarde, que s√£o falhas caras.\nCustomer collaboration over contract negotiation\nTamb√©m √© poss√≠vel que haja um m√° levantamento de requisitos durante o in√≠cio do projeto, pois muitas vezes o pr√≥prio cliente/usu√°rio n√£o conseguiu prever todas as funcionalidades necess√°rias.\nPodemos descrever essa situa√ß√£o como:\n Do ponto A √© poss√≠vel ver apenas o ponto B; Do ponto B √© poss√≠vel ver o ponto C;  Portanto h√° um grande incentivo para que o software seja entregue em partes, continuamente. Colhendo assim os feedbacks do usu√°rio sobre os pr√≥ximos passos, seguindo os conceitos de prototipa√ß√£o evolutiva, que foram muito divulgados por meio do livro The Lean Startup.\nEsse ponto faz muito contraste com o anterior, em rela√ß√£o √† entrega cont√≠nua (continuous release), para que seja poss√≠vel apresentar o prot√≥tipo e evoluir ele ao longo do projeto.\nSaiba quem √© o seu cliente/consumidor/usu√°rio, e para quem voc√™ est√° fazendo o software, pois esse √© o √∫nico jeito de conseguir entregar valor para esse cliente. Parte importante do processo de desenvolvimento de software √© ser emp√°tico com os problemas do usu√°rio, e entender de verdade qual √© o problema a ser resolvido, e o resultado causado pelo impacto no desenvolvimento do software (gera√ß√£o do valor para o usu√°rio).\nResponding to change over following a plan\nFazer um redesign dos requisitos durante o projeto √© parte crucial para o sucesso do projeto. Ser√° o √∫nico jeito de conseguir trazer para a mesa todos os problemas do usu√°rio, e criar a melhor solu√ß√£o para todos esses problemas, pois s√≥ o usu√°rio sabe dos reais problemas que ele enfrenta no dia-a-dia lidando com o software.\nCom a entrega cont√≠nua de software junto com o monitoramento dos resultados, o processo de coleta dos feedbacks fica muito mais simples e r√°pido.\nDevOps, DevOps, DevOps Com a divulga√ß√£o da palavra DevOps, existe muita gente falando sobre DevOps por a√≠. Existindo muita diverg√™ncia no que √© falado, e criando uma confus√£o grande sobre o tema. Acaba sendo muito comum se deparar com diferentes interpreta√ß√µes sobre o que √© DevOps. Existe muito eufemismo na √°rea, e gourmetiza√ß√£o em cima do LinkedIn, com muitos SysAdmins por a√≠ se dizendo DevOps, pois aprenderam a codar shell script dentro do Python.\nT√° afim de continuar lendo? D√° uma olhada nos benef√≠cios de implementar DevOps.\n","date":1547240400,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1592457555,"objectID":"1ea695d486767aac5f192dfd0ddf47d4","permalink":"https://macunha.me/pt/post/2019/01/devops-genesis/","publishdate":"2019-01-11T21:00:00Z","relpermalink":"/pt/post/2019/01/devops-genesis/","section":"post","summary":"De onde vieram e para onde v√£o. DevOps n√£o √© apenas automa√ß√£o, mas sim uma cultura √°gil para neg√≥cios","tags":["devops","culture","agile","lean"],"title":"DevOps: Genesis","type":"post"},{"authors":null,"categories":null,"content":"Introdu√ß√£o Sum√°rio Como propriet√°rio do maior conjunto de dados de m√≠dia do Brasil, o l√≠der em monitoramento de m√≠dia Clipping Service estava com problemas de escalabilidade, aproximando-se da capacidade m√°xima de seu data center e de seus \u0026ldquo;leitores\u0026rdquo;.\nClipping Service opera em grande escala, recebendo cerca de ~4,5K p√°ginas de m√≠dia por dia de cerca de 300 jornais, tanto na vers√£o digital como na impressa. Anteriormente os funcion√°rios chamados de \u0026ldquo;leitores\u0026rdquo; eram respons√°veis pela leitura e clipping (adicionando destaque ao conte√∫do alvo) para depois serem repassados para a equipe de \u0026ldquo;revisores\u0026rdquo;.\nComo se o fardo de ler in√∫meras p√°ginas por dia n√£o fosse suficiente, a opera√ß√£o dos leitores come√ßa por volta das 4:30 da manh√£ quando a \u0026ldquo;primeira leitura\u0026rdquo; inicia (ou seja, a entrega dos impressos matinais).\nProblema Por mais de 20 anos este conte√∫do foi ingerido pelos chamados \u0026ldquo;leitores\u0026rdquo;. Mas, devido ao advento da internet e do boom da imprensa digital a partir do final dos anos 90, e atualmente de m√≠dias social as empresas est√£o transferindo seus investimentos de clipping para o monitoramento de outras √°reas. Exigindo portanto uma a√ß√£o do Clipping Service para se manter competitiva no mercado.\nAtrav√©s da automa√ß√£o da leitura de not√≠cias usando OCR, PLN e intelig√™ncia artificial para categorizar as m√≠dias, o plano era alcan√ßar um maior rendimento durante a ingest√£o, dando aos leitores mais tempo livre para revisar o conte√∫do. Consequentemente, alcan√ßar uma maior qualidade no conte√∫do, j√° que n√≥s como humanos n√£o somos bons em fazer tarefas repetitivas, especialmente quando se trata de ler p√°ginas intermin√°veis em busca de nomes e palavras.\nSolu√ß√£o Implementa√ß√£o t√©cnica Ap√≥s algum tempo de pesquisa e benchmarking das alternativas, decidimos usar Python como linguagem de implementa√ß√£o para lidar com textos, OCR e PLN (usando NLTK). Dada sua API estendida e bibliotecas para PLN e processamento de imagens.\nComo fornecedor de nuvem escolhemos AWS devido a sua estabilidade e consist√™ncia em rela√ß√£o a outros fornecedores, a conclus√£o na √©poca foi: AWS possui uma estimativa de pre√ßo 14,67% maior do que a GCP. Entretanto, a popularidade da AWS √© maior do que a GCP, assim como √© uma nuvem comprovada em termos de estabilidade, suporte e integridade. Fazendo uma escolha mais segura por um pre√ßo ligeiramente superior.\nA stack foi: Python 3 usando Dramatiq como biblioteca de processamento de tarefas, executando OCR por meio do Tesseract, processando texto com NLTK e imagens com Pillow (wrapper do ImageMagick). Redis foi o mensage broker do Dramatiq, um banco relacional simples estava no Postgres armazenando m√©tricas referentes √† execu√ß√£o e t√≠nhamos tamb√©m um Elasticsearch armazenando o conte√∫do processado.\nAs solicita√ß√µes vindas do data center chegaram a um Gateway API, respons√°vel por executar uma fun√ß√£o Lambda, e entregar o resultado do conte√∫do.\nA melhor parte do design? Armazen√°vamos e servimos o conte√∫do por meio do AWS S3. Cada pe√ßa foi desenhada com toler√¢ncia a falhas, e n√≥s simplesmente deslig√°vamos toda a infra-estrutura em nuvem depois da opera√ß√£o, para ligar apenas no dia seguinte.\nOperando apenas das 4h √†s 14h, um projeto \u0026ldquo;serverless\u0026rdquo; e ef√™mero com beneficiado por uma redu√ß√£o de custos em n√∫vem agressiva.\nImpacto e resultados A Clipping Service reduziu em ~78% o quadro de funcion√°rios da equipe de leitura, oferecendo contrata√ß√£o interna para outras √°reas da empresa e um plano de demiss√£o volunt√°rio com benef√≠cios, tornando o processo o mais humano poss√≠vel para os funcion√°rios que preferissem sair.\nUtilizando automa√ß√£o para tarefas de leitura, a Clipping Service p√¥de alcan√ßar melhorias consider√°veis durante o processo de ingest√£o de m√≠dia (cerca de 20 vezes mais r√°pido), oferecendo maior qualidade no servi√ßo de clipping para seus clientes e viu a oportunidade de criar posteriormente um servi√ßo de auto-servi√ßo de recortes de imprensa, uma vez que o custo operacional diminuiu significativamente.\n","date":1536624e3,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1614436244,"objectID":"37eaa15cd4e0a0d9956a244d4854656c","permalink":"https://macunha.me/pt/project/clipping-service-news-ocr/","publishdate":"2018-09-11T00:00:00Z","relpermalink":"/pt/project/clipping-service-news-ocr/","section":"project","summary":"Automa√ß√£o do processo de leitura na Clipping Service durante o monitoramento de m√≠dias e not√≠cias, por meio de intelig√™ncia artificial, OCR e PLN. Proporcionando um maior throughput √† opera√ß√£o e criando uma verdadeira infra-estrutura serverless para expandir seu Data Center.","tags":["cloud","serverless","nlp"],"title":"Clipping Service News OCR","type":"project"},{"authors":null,"categories":null,"content":"Introdu√ß√£o Sum√°rio Para poder inovar e se manter em um mercado em constante mudan√ßa e evolu√ß√£o, Dotz passou por um processo de transforma√ß√£o digital e teve a ajuda de alguns consultores neste percurso.\nEntre as iniciativas para se aproximar de um modelo digital, surgiu a implementa√ß√£o de um Data Lake, com o requisito de ser serverless e cloud-native, auxiliando no processo de tomada de decis√£o e encurtando o time-to-market durante o lan√ßamento de novos produtos.\nProblem√°tica A Dotz √© uma das maiores empresas no campo de programas de fidelidade no Brasil, e enfrentaria um grande n√∫mero de problemas com desconex√£o de dados dificultando a an√°lise do comportamento de seus usu√°rios. Como eles receberam dados de in√∫meros supermercados e lojas, √© dif√≠cil agrupar os produtos, j√° que o nome √© diferente dependendo da fonte. Para ajudar nesta an√°lise, eles decidiram construir um Data Lake.\nSolu√ß√£o Implementa√ß√£o T√©cnica Constru√≠mos e implantamos uma arquitetura gerenciada da Big Data usando a Plataforma Cloud do Google (GCP) para suportar esta estrat√©gia e permitir uma vis√£o de 360 graus dos clientes (usu√°rios com pontos a.k.a. Dotz) e parceiros que oferecem o programa de fidelidade.\nO design foi focado em servi√ßos ger√™nciados pela nuvem e serverless oferecida pelo Google, servindo as principais compet√™ncias de um Data Lake como o armazenamento escal√°vel usando o Google Cloud Storage, e o Google BigQuery. Com parte do processo rodando containerizado em Kubernetes, respons√°vel pela limpeza de dados e gerenciar o ETL.\nTransmitimos dados com o Apache Beam rodando sob o Google DataFlow, processamento em massa paralelo com Apache Spark jobs executados no Google DataProc, an√°lise explorat√≥ria com o Google DataLab, Machine Learning Analysis com o Google ML e visualiza√ß√£o de dados no Google Data Studio.\nOs dados s√£o transportados por meio de um modelo data-driven, onde os dados foram planejados para streaming, including o ETL (que funciona em um micro-batch, para permitir a explora√ß√£o em near-real-time). Estes dados passam pelo pipeline de dados utilizando o servi√ßo de mensageria do Google Pub/Sub, em que cada mensagem √© serializada utilizando o formato Avro, reduzindo a carga e permitindo que o transporte seja econ√¥mico, r√°pido e confi√°vel.\nImpacto e resultados Tudo isso permitiu √† Dotz ter uma melhor estrutura em sua plataforma anal√≠tica, previamente gerenciada em uma grande inst√¢ncia do MS SQL Server, sendo deslocada para um Data Lake com camadas que permitem a categoriza√ß√£o, governan√ßa, qualidade e seguran√ßa dos dados.\nSuporte a processos anal√≠ticos de dados dos usu√°rios, explora√ß√£o √°gil e monetiza√ß√£o de seus conhecimentos sobre o comportamento dos clientes.\n","date":1518825600,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1614436244,"objectID":"77b5cc8bb1617a1cae6f5270c724940d","permalink":"https://macunha.me/pt/project/dotz-data-labs/","publishdate":"2018-02-17T00:00:00Z","relpermalink":"/pt/project/dotz-data-labs/","section":"project","summary":"Arquitetura de Big Data Serverless e cloud-managed usando Google's Cloud Platform (GCP) para suportar uma vis√£o 360-graus dos clientes e parceiros da Dotz, uma das maiores empresas na √°rea de programas de fidelidade no Brazil","tags":["data-engineering"],"title":"Dotz Data Labs","type":"project"},{"authors":null,"categories":null,"content":"Introdu√ß√£o Sum√°rio Dentro do planejamento anual da Easynvest, um investimento na expans√£o da equipe de data \u0026amp; analytics teve como objetivo encurtar a tomada de decis√£o e entregar maior qualidade aos clientes por meio de um processo operacional com baixo custo.\nDentre os principais objetivos deste projeto, tivemos a automatiza√ß√£o de an√°lise de cr√©dito na aprova√ß√£o do cadastro de clientes utilizando Machine Learning, um processo que at√© ent√£o era longo e manual, sendo realizado pelo back office.\nSeguido de uma melhor oferta de produtos ao cliente, realizando a categoriza√ß√£o de acordo com o perfil de cada cliente, permitindo sugest√µes mais atraentes de produtos, estando alinhadas com as prefer√™ncias pessoais, assim como de acordo com o perfil de cada investidor (conservador, moderado ou agressivo).\nPor √∫ltimo, mas n√£o menos importante, a detec√ß√£o inteligente de lavagem de dinheiro gerando relat√≥rios para as autoridades respons√°veis.\nProblem√°tica Entretanto, houve limita√ß√µes nas ferramentas de dados, principalmente devido ao fato de seram softwares propriet√°rios (com licen√ßas limitadas) e projetados para uso em data centers. Al√©m disso, o banco de dados anal√≠tico foi modelado para modelos tradicionais de Business Intelligence (OLAP, etc), tornando o processo de tomada de decis√£o pesado, devido √† quantidade exigente de intera√ß√µes durante o ETL.\nAnteriormente para um cliente ser aprovado, o processo levava de 10 a 15 dias. Para que todas as informa√ß√µes necess√°rias fossem coletadas, tendo uma perspectiva completa do perfil, includindo an√°lises de cr√©dito. Ap√≥s coletar as informa√ß√µes o back office gerava uma pontua√ß√£o na an√°lise interna de cr√©dito.\nSendo que, na maioria dos casos, o cliente n√£o era notificado sobre atualiza√ß√µes referentes ao processo e n√£o recebia feedback ao fim (caso recusado), a menos que fosse explicitamente solicitado (contatando o suporte via chat ou e-mail, por exemplo) o que tornava o processo demorado e custoso. Sem contar as in√∫meras quantidades de clientes perdidos para a concorr√™ncia durante esta longa espera.\nSolu√ß√£o Implementa√ß√£o T√©cnica Para tornar isso poss√≠vel, constru√≠mos uma implementa√ß√£o h√≠brida em nuvem usando AWS componentes baseados em nuvem (principalmente AWS S3, EMR e ECS), para extender a capacidade do data center, implementando um ecossistema Hadoop cloud-first (substituindo os componentes de software propriet√°rio por open-source equivalentes). Dando √† Easynvest a possibilidade de crescer seu Data Lake exponencialmente.\nO design do Data Lake foi robusto, visando lidar com a execu√ß√£o pesada de processos anal√≠ticos atrav√©s de modelos de Machine Learning, com suporte para data quality, governan√ßa de metadados, seguran√ßa da informa√ß√£o e self-service de dados (os propriet√°rios dos dados poderiam compartilhar seus dados com consumidores de outras √°reas da empresa, permitindo o auto-servi√ßo de seus dados anal√≠ticos).\nUm Chatbot tamb√©m foi utilizado para reduzir a carga operacional no ambiente, sendo respons√°vel pela manuten√ß√£o e atualiza√ß√£o dos componentes de infra-estrutura. Desde o acionamento de deployments at√© a gera√ß√£o de chaves de criptografia on-demand para seguran√ßa e governan√ßa da plataforma de dados. Implementado com Errbot em Python interagindo com Slack.\nIndo al√©m, implementamos as melhores pr√°ticas de DevOps, tendo Jenkins como ferramenta para CI/CD dos componentes desenvolvidos junto com Ansible para Gerenciamento da Configura√ß√£o.\nImpacto e resultados Gra√ßas √† utiliza√ß√£o de camadas no Data Lake e a implementa√ß√£o de pipelines de dados, conseguimos reduzir o tempo de ingest√£o dos dados em 78%, incluindo metadados e cat√°logo de dados, al√©m de automatizar grande parte do trabalho que antes era feito manualmente durante a ingest√£o.\nAssim, trazendo resultados positivos, principalmente durante a aprova√ß√£o de novos registros de usu√°rios, de ~10 dias para aproximadamente 1 dia. Tornando tamb√©m a plataforma de dados mais democr√°tica, fornecendo informa√ß√µes relevantes que facilita a an√°lise de outras √°reas da companhia como risco (an√°lise de cr√©dito) e suporte (atendimento), sem ter que abrir m√£o da seguran√ßa.\n","date":149904e4,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1614436244,"objectID":"580efc08ed44412bc39d6faa75ae1605","permalink":"https://macunha.me/pt/project/easynvest-data-platform/","publishdate":"2017-07-03T00:00:00Z","relpermalink":"/pt/project/easynvest-data-platform/","section":"project","summary":"Hybrid-cloud Data Lake com a maior parte de seus componentes na AWS. Entre os principais objetivos, t√≠nhamos a automatiza√ß√£o da an√°lise de cr√©dito, campanhas dirigidas aos investidores de acordo com o perfil e a detec√ß√£o inteligente de lavagem de dinheiro","tags":["data-engineering"],"title":"Easynvest Data Platform","type":"project"},{"authors":null,"categories":null,"content":"Introdu√ß√£o Sum√°rio JSL Holdings Ltda, detentora da Julio Sim√µes Logistica (maior player LATAM de log√≠stica) comprou a Movida Rent a Car em 2013 para expandir o portf√≥lio e abrir novas oportunidades no mercado de loca√ß√£o e venda de ve√≠culos mercados.\nA JSL investiu em torno de R$ 1,8 bilh√£o na Movida, e multiplicou a receita em 21 vezes de R$ 58m para R$ 1,2b, em 3 anos. Com base nestes resultados de sucesso, a JSL Holdings Ltd planejou um IPO para a Movida.\nProblem√°tica Para ser negociada em bolsa, a Movida teria que passar por uma auditoria. Por√©m a solu√ß√£o de software n√£o estava de acordo com algumas normas de seguran√ßa.\nO projeto come√ßou em Dezembro de 2016, planejando a implementa√ß√£o de um processo de autom√°tizado de publica√ß√£o de software adotando DevOps em seu data center. Com os seguintes objetivos:\n seguran√ßa; nenhuma pessoa deveria acessar os servidores Linux. e produtividade; liberando recursos mais rapidamente para encurtar o time-to-market de novas features.  Solu√ß√£o Implementa√ß√£o T√©cnica Nosso primeiro objetivo era implementar o pipeline suportando CI/CD utilizando Jenkins, respons√°vel por empacotar novas funcionalidades, criar um deployment e implement√°-lo no data center. Al√©m do deployment em produ√ß√£o, o pipeline tamb√©m apoiou a cria√ß√£o de ambientes on-demand para homologa√ß√£o de recursos e coleta de feedback dos usu√°rios.\nPara ter um ciclo de aprova√ß√£o mais r√°pido e controlado, migramos o servidor Git para dentro do data center. Atrav√©s desta a√ß√£o n√≥s reduziu em 5 minutos (62%) do tempo total de deployment e aumentamos o controle sobre os acessos em seus reposit√≥rios.\nA implementa√ß√£o de CI/CD utilizou Jenkins Pipeline para CI/CD, GitLab com autentica√ß√£o LDAP, e Ansible como Configuration Manager. Um deployment completo leva cerca de 2 minutos desde o git push at√© o c√≥digo estar em produ√ß√£o.\nAl√©m da implanta√ß√£o de um pipeline para CI/CD, tamb√©m trabalhamos em uma estrat√©gia de self-service para a execu√ß√£o de jobs sem acesso direto por SSH aos servidores. Rundeck entrou em cena, com configura√ß√µes de RBAC e visibilidade sobre o hist√≥rico de jobs executados.\nImpacto e resultados Movida foi auditada em Janeiro 2017, no final de Janeiro de 2017 eles receberam a aprova√ß√£o.\nDuas semanas depois, em fevereiro de 2017, a Movida lan√ßou seu IPO, marcado como o primeiro IPO brasileiro de 2017. Abrindo seu capital no dia 8 de Fevereiro de 2017, levantando cerca de R$ 645M.\n","date":1486425600,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1628755196,"objectID":"93741282d0ca2cf089c037ab75b0cfad","permalink":"https://macunha.me/pt/project/movida-rent-a-devops/","publishdate":"2017-02-07T00:00:00Z","relpermalink":"/pt/project/movida-rent-a-devops/","section":"project","summary":"Projeto inicial de DevOps na Movida, respons√°vel pela implementa√ß√£o da base para pipelines de CI/CD, ger√™ncia de configura√ß√£o e melhorias na seguran√ßa dos servidores.","tags":["devops"],"title":"Movida Rent A DevOps","type":"project"},{"authors":null,"categories":null,"content":"Introdu√ß√£o Sum√°rio A Nextel planejou desenvolver uma aplica√ß√£o m√≥vel para reduzir seus custos operacionais com call centers e reduzir o contact rate. \u0026ldquo;Nextel Digital\u0026rdquo; foi o nome dado ao projeto respons√°vel por lan√ßar esta aplica√ß√£o.\nCom o tempo, o projeto \u0026ldquo;Nextel Digital\u0026rdquo; absorveu mais objetivos, como melhorar a user experience, e se tornou um novo produto chamado \u0026ldquo;Happy\u0026rdquo;, uma operadora de telefonia digital. Nextel Happy permite que os usu√°rios gerenciem seus planos e dados completamente pelo aplicativo, desde a ativa√ß√£o do seu SIM at√© a gest√£o de plano familiar.\nEste projeto ajudou a Nextel a aumentar sua base de clientes, melhorando a experi√™ncia dos usu√°rios, e diminuir os custos operacionais (em 16%).\nProblem√°tica A equipe executiva da Nextel Brasil decidiu trabalhar com terceiriza√ß√£o no desenvolvimento deste produto para absorver conhecimento das empresas e para complementar suas capacidades internas. Assim como trazer diferentes perspectivas em jogo, melhorando o processo criativo.\nNossa equipe assumiu a responsabilidade de arquitetar e implementar a infraestrutura de n√∫vem garantindo alta disponibilidade, resili√™ncia e consist√™ncia do software.\nAssim como assumimos a responsabilidade de sincronizar os dados entre o data center da Nextel e a nuvem. Movendo com seguran√ßa uma quantia grande em GB de dados relacionados √† consumo para a n√∫vem diariamente, sem perda ou duplica√ß√£o dos dados.\nSolu√ß√£o Implementa√ß√£o t√©cnica k Escolhemos o GlusterFS para garantir a consist√™ncia, instalado entre o data center da Nextel e a AWS, sincronizando os dados de usu√°rios (ex.: consumo do plano de dados, minutos de chamada). A equipe de opera√ß√µes da Nextel IT alimentava o GlusterFS diretamente com os dados de torres telef√¥nicas, permitindo processamento em near-real-time.\nAssim que os dados estavam dispon√≠veis no volume montado em inst√¢ncias na AWS, a implementa√ß√£o em Celery entra em jogo. No centro da arquitetura, o Celery (implementado em Python 3) usando Redis como message broker, executa jobs ass√≠ncronos para inspecionar eventos no GlusterFS.\nUma vez que o Celery detecta um novo arquivo dispon√≠vel ele analisa o conte√∫do e inicia um multipart upload para o AWS S3, em seguida compara os checksums para garantir a consist√™ncia (e retenta em caso de inconsist√™ncia).\nAp√≥s chegar ao AWS S3, o evento do objeto aciona uma fun√ß√£o AWS Lambda para analisar o conte√∫do e index√°-lo no Elasticsearch, sendo posteriormente servido aos clientes atrav√©s de uma API REST.\nToda o design da infrastrutura foi planejada para ser imut√°vel, facilitando a evolu√ß√£o e confiabilidade, tendo Ansible como Configuration Manager e AWS CloudFormation como provisionador na nuvem. Em apenas alguns minutos √© poss√≠vel recriar todo o ecossistema, com esfor√ßo m√≠nimo.\nImpacto e resultados Todo o processo de disponibiliza√ß√£o dos dados de uma torre celular que tomava em torno de 1 dia foi reduzido para 5 minutos. Como consequ√™ncia, o tempo de dura√ß√£o das chamadas nos call center caiu ~56%, devido √† alternativa de self-service fornecida no aplicativo.\nAl√©m disso, os usu√°rios podem gerenciar seu hist√≥rico de chamadas e planejar o consumo diretamente pelo celular, com atualiza√ß√µes em near-real-time. Proporcionano um feedback consistente e interativo.\n","date":1480464e3,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1614436244,"objectID":"1073e038aa43617508121808c32c547e","permalink":"https://macunha.me/pt/project/nextel-digital-release/","publishdate":"2016-11-30T00:00:00Z","relpermalink":"/pt/project/nextel-digital-release/","section":"project","summary":"Projeto de transforma√ß√£o digital na Nextel do Brasil, que evoluiu para um produto chamado \"Happy\", uma operadora de telefonia digital. Melhorando a experi√™ncia dos usu√°rios e reduzindo custos operacionais.","tags":["devops"],"title":"Nextel Digital Release","type":"project"}]